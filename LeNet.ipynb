{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "infectious-margin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /anaconda3/include/python3.6m/UNKNOWN\n",
      "sysconfig: /anaconda3/include/python3.6m\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Requirement already satisfied: ipynb in /anaconda3/lib/python3.6/site-packages (0.5.1)\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /anaconda3/include/python3.6m/UNKNOWN\n",
      "sysconfig: /anaconda3/include/python3.6m\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worldwide-theory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Id                      Old_Id  \\\n",
      "0  ./People_after/Ennie/Ennie07.JPG  ./People/Ennie/Ennie07.JPG   \n",
      "1  ./People_after/Ennie/Ennie06.JPG  ./People/Ennie/Ennie06.JPG   \n",
      "2  ./People_after/Ennie/Ennie10.JPG  ./People/Ennie/Ennie10.JPG   \n",
      "3  ./People_after/Ennie/Ennie04.JPG  ./People/Ennie/Ennie04.JPG   \n",
      "4  ./People_after/Ennie/Ennie05.JPG  ./People/Ennie/Ennie05.JPG   \n",
      "\n",
      "      Folder_Name   Image_Name Person_Name  Labels  \n",
      "0  ./People/Ennie  Ennie07.JPG       Ennie       1  \n",
      "1  ./People/Ennie  Ennie06.JPG       Ennie       1  \n",
      "2  ./People/Ennie  Ennie10.JPG       Ennie       1  \n",
      "3  ./People/Ennie  Ennie04.JPG       Ennie       1  \n",
      "4  ./People/Ennie  Ennie05.JPG       Ennie       1   \n",
      "\n",
      "                                    Id                        Old_Id  \\\n",
      "45  ./People_after/Teresa/Teresa02.JPG  ./People/Teresa/Teresa02.JPG   \n",
      "46  ./People_after/Teresa/Teresa03.JPG  ./People/Teresa/Teresa03.JPG   \n",
      "47  ./People_after/Teresa/Teresa01.JPG  ./People/Teresa/Teresa01.JPG   \n",
      "48  ./People_after/Teresa/Teresa08.JPG  ./People/Teresa/Teresa08.JPG   \n",
      "49  ./People_after/Teresa/Teresa09.JPG  ./People/Teresa/Teresa09.JPG   \n",
      "\n",
      "        Folder_Name    Image_Name Person_Name  Labels  \n",
      "45  ./People/Teresa  Teresa02.JPG      Teresa       5  \n",
      "46  ./People/Teresa  Teresa03.JPG      Teresa       5  \n",
      "47  ./People/Teresa  Teresa01.JPG      Teresa       5  \n",
      "48  ./People/Teresa  Teresa08.JPG      Teresa       5  \n",
      "49  ./People/Teresa  Teresa09.JPG      Teresa       5  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7e8402dff74126aeaa6a79b665bed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import dataframe which stores information of the dataset\n",
    "from ipynb.fs.full.ImageProcessing_LeNet import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pending-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import used libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dropout, Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "serial-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-investing",
   "metadata": {},
   "source": [
    "## Model Defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "three-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet:\n",
    "    \"\"\"LeNet Architecture\"\"\"\n",
    "    def build():  \n",
    "        # initialize the model  \n",
    "        model = Sequential()  \n",
    "   \n",
    "        # first set of CONV => tanh => POOL  \n",
    "        model.add(Conv2D(16, (5, 5), activation='tanh', input_shape=(64, 64, 3)))  \n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "   \n",
    "        # second set of CONV => relu => POOL  \n",
    "        model.add(Conv2D(32, (5, 5)))  \n",
    "        model.add(Activation(\"tanh\"))  \n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "   \n",
    "        # first set of Flatten => relu layers  \n",
    "        model.add(Flatten())  \n",
    "        model.add(Dense(120))  \n",
    "        model.add(Activation(\"tanh\"))  \n",
    "        \n",
    "        # second set of Flatten => relu layers  \n",
    "        model.add(Flatten())  \n",
    "        model.add(Dense(84))  \n",
    "        model.add(Activation(\"tanh\"))\n",
    "    \n",
    "        # softmax classifier  \n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "        # return the constructed network architecture  \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "floral-title",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 60, 60, 16)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        12832     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 120)               649080    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 84)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 425       \n",
      "=================================================================\n",
      "Total params: 673,717\n",
      "Trainable params: 673,717\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = LeNet.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "prescription-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-piece",
   "metadata": {},
   "source": [
    "## Model Compiling with different optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-today",
   "metadata": {},
   "source": [
    "Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "lined-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet_SGD = LeNet.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "neutral-stake",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_SGD = keras.optimizers.SGD(lr=0.01)  \n",
    "LeNet_SGD.compile(loss=\"categorical_crossentropy\", optimizer=opt_SGD, metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "occupied-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet_SGD_model_checkpoint = ModelCheckpoint('face_detect_LeNet_SGD.h5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-teddy",
   "metadata": {},
   "source": [
    "Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "forced-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet_Adam = LeNet.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "alone-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_Adam = keras.optimizers.Adam(lr=0.01)\n",
    "LeNet_Adam.compile(loss=\"categorical_crossentropy\", optimizer=opt_Adam, metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "quarterly-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet_Adam_model_checkpoint = ModelCheckpoint('face_detect_LeNet_Adam.h5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-links",
   "metadata": {},
   "source": [
    "Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "behind-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet_Adagrad = LeNet.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "polyphonic-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_Adagrad = keras.optimizers.Adagrad(lr=0.01)\n",
    "LeNet_Adagrad.compile(loss=\"categorical_crossentropy\", optimizer=opt_Adagrad, metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "civilian-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet_Adagrad_model_checkpoint = ModelCheckpoint('face_detect_LeNet_Adagrad.h5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-calculator",
   "metadata": {},
   "source": [
    "Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "removed-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet_Adadelta = LeNet.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "magnetic-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_Adadelta = keras.optimizers.Adadelta(lr=0.01)\n",
    "LeNet_Adadelta.compile(loss=\"categorical_crossentropy\", optimizer=opt_Adadelta, metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "documentary-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet_Adadelta_model_checkpoint = ModelCheckpoint('face_detect_LeNet_Adadelta.h5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-steal",
   "metadata": {},
   "source": [
    "Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "creative-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet_Nadam = LeNet.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "metropolitan-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_Nadam = keras.optimizers.Nadam(lr=0.01)\n",
    "LeNet_Nadam.compile(loss=\"categorical_crossentropy\", optimizer=opt_Nadam, metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "external-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet_Nadam_model_checkpoint = ModelCheckpoint('face_detect_LeNet_Nadam.h5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-watch",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "isolated-musical",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds=5\n",
    "epochs=30\n",
    "batch_size=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dangerous-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size=0.1, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "metropolitan-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to fit the model\n",
    "def fit_and_evaluate(model, x_train, x_valid, x_test, y_train, y_valid, y_test, model_checkpoint):\n",
    "    history = None\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        callbacks=[early_stopping, model_checkpoint],\n",
    "                        validation_data=(x_valid, y_valid))  \n",
    "    print(\"Val Score: \", model.evaluate(x_test, y_test))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-humanity",
   "metadata": {},
   "source": [
    "Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fleet-flour",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Fold:  1\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 1s 202ms/step - loss: 1.8334 - accuracy: 0.1730 - val_loss: 2.0107 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.01067, saving model to face_detect_LeNet_SGD.h5\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.7593 - accuracy: 0.1325 - val_loss: 1.7739 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.01067 to 1.77393, saving model to face_detect_LeNet_SGD.h5\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 1.6222 - accuracy: 0.3119 - val_loss: 1.7296 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.77393 to 1.72960, saving model to face_detect_LeNet_SGD.h5\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1.4831 - accuracy: 0.4456 - val_loss: 1.6999 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.72960 to 1.69994, saving model to face_detect_LeNet_SGD.h5\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 1.3950 - accuracy: 0.6007 - val_loss: 1.6131 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.69994 to 1.61311, saving model to face_detect_LeNet_SGD.h5\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 1.3801 - accuracy: 0.5677 - val_loss: 1.5706 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.61311 to 1.57060, saving model to face_detect_LeNet_SGD.h5\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1.2884 - accuracy: 0.5804 - val_loss: 1.8925 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.57060\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 1.2374 - accuracy: 0.6146 - val_loss: 1.8218 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.57060\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 1.2005 - accuracy: 0.6117 - val_loss: 1.7544 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.57060\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 1.1046 - accuracy: 0.8177 - val_loss: 1.4887 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.57060 to 1.48869, saving model to face_detect_LeNet_SGD.h5\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 1.0842 - accuracy: 0.7442 - val_loss: 1.6056 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.48869\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.9322 - accuracy: 0.8519 - val_loss: 1.8864 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.48869\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.8472 - accuracy: 0.7697 - val_loss: 1.7252 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.48869\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.8030 - accuracy: 0.8356 - val_loss: 1.5439 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.48869\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.7467 - accuracy: 0.8941 - val_loss: 1.8602 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.48869\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.5593 - accuracy: 0.3333\n",
      "Val Score:  [1.5592751502990723, 0.3333333432674408]\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  2\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.1494 - accuracy: 0.6111 - val_loss: 1.9864 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.48869\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.1305 - accuracy: 0.6667 - val_loss: 1.9902 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.48869\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.0321 - accuracy: 0.7222 - val_loss: 1.8330 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.48869\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.9630 - accuracy: 0.7500 - val_loss: 1.7550 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.48869\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8973 - accuracy: 0.8056 - val_loss: 1.4949 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.48869\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.7924 - accuracy: 0.9444 - val_loss: 1.6242 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.48869\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.6822 - accuracy: 0.9722 - val_loss: 1.8001 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.48869\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.6425 - accuracy: 0.9167 - val_loss: 1.8533 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.48869\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.5544 - accuracy: 0.9722 - val_loss: 2.2097 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.48869\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.5394 - accuracy: 0.9444 - val_loss: 2.1145 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.48869\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0163 - accuracy: 0.6667\n",
      "Val Score:  [1.0162816047668457, 0.6666666865348816]\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  3\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.9118 - accuracy: 0.8056 - val_loss: 1.5872 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.48869\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.8507 - accuracy: 0.8611 - val_loss: 1.4825 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.48869 to 1.48250, saving model to face_detect_LeNet_SGD.h5\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.7335 - accuracy: 0.9167 - val_loss: 1.4758 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.48250 to 1.47576, saving model to face_detect_LeNet_SGD.h5\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.6757 - accuracy: 0.9167 - val_loss: 1.7152 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.47576\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.5999 - accuracy: 0.9444 - val_loss: 1.3667 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.47576 to 1.36667, saving model to face_detect_LeNet_SGD.h5\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.5640 - accuracy: 0.9722 - val_loss: 1.4768 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.36667\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.4880 - accuracy: 0.9444 - val_loss: 1.1675 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.36667 to 1.16746, saving model to face_detect_LeNet_SGD.h5\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4427 - accuracy: 0.9722 - val_loss: 1.1150 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.16746 to 1.11500, saving model to face_detect_LeNet_SGD.h5\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.4036 - accuracy: 1.0000 - val_loss: 1.5203 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.11500\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3679 - accuracy: 1.0000 - val_loss: 1.1170 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.11500\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.3304 - accuracy: 1.0000 - val_loss: 1.3244 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.11500\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3023 - accuracy: 1.0000 - val_loss: 1.1899 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.11500\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.2796 - accuracy: 0.9722 - val_loss: 1.3777 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.11500\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6133 - accuracy: 0.7778\n",
      "Val Score:  [0.6133020520210266, 0.7777777910232544]\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  4\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.4467 - accuracy: 1.0000 - val_loss: 1.5404 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.11500\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.3917 - accuracy: 1.0000 - val_loss: 1.6509 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.11500\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.3381 - accuracy: 1.0000 - val_loss: 1.6196 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.11500\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.3028 - accuracy: 1.0000 - val_loss: 1.6988 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.11500\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.2736 - accuracy: 1.0000 - val_loss: 1.5778 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.11500\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.2544 - accuracy: 1.0000 - val_loss: 1.5623 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.11500\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4547 - accuracy: 0.7778\n",
      "Val Score:  [0.454694539308548, 0.7777777910232544]\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  5\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.4141 - accuracy: 0.9444 - val_loss: 1.1283 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.11500\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.3655 - accuracy: 1.0000 - val_loss: 1.4836 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.11500\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.3339 - accuracy: 0.9722 - val_loss: 1.2372 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.11500\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.2890 - accuracy: 1.0000 - val_loss: 1.0774 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.11500 to 1.07744, saving model to face_detect_LeNet_SGD.h5\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.2756 - accuracy: 1.0000 - val_loss: 1.1589 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.07744\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.2525 - accuracy: 1.0000 - val_loss: 1.2097 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.07744\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.2297 - accuracy: 1.0000 - val_loss: 1.2587 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.07744\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.2040 - accuracy: 1.0000 - val_loss: 1.3607 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.07744\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.1822 - accuracy: 1.0000 - val_loss: 1.2753 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.07744\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3518 - accuracy: 1.0000\n",
      "Val Score:  [0.35179054737091064, 1.0]\n",
      "====================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#save the model history in a list after fitting so that we can plot later\n",
    "LeNet_SGD_history = [] \n",
    "\n",
    "for i in range(n_folds):\n",
    "    print(\"Training on Fold: \",i+1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, \n",
    "                                               random_state = np.random.randint(1,500, 1)[0])\n",
    "    LeNet_SGD_history.append(fit_and_evaluate(LeNet_SGD, x_train, X_valid, x_test,\n",
    "                                              y_train, Y_valid, y_test, LeNet_SGD_model_checkpoint))\n",
    "    print(\"=======\"*12, end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-ownership",
   "metadata": {},
   "source": [
    "Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "greater-voluntary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Fold:  1\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 1s 88ms/step - loss: 2.7043 - accuracy: 0.1927 - val_loss: 3.6733 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.67328, saving model to face_detect_LeNet_Adam.h5\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 2.7454 - accuracy: 0.1719 - val_loss: 2.8458 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.67328 to 2.84581, saving model to face_detect_LeNet_Adam.h5\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 1.8955 - accuracy: 0.2662 - val_loss: 1.7280 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.84581 to 1.72798, saving model to face_detect_LeNet_Adam.h5\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 1.6667 - accuracy: 0.1875 - val_loss: 1.6629 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.72798 to 1.66294, saving model to face_detect_LeNet_Adam.h5\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1.6861 - accuracy: 0.1163 - val_loss: 2.1205 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.66294\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 1.5715 - accuracy: 0.1308 - val_loss: 2.0291 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.66294\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 1.6663 - accuracy: 0.2610 - val_loss: 1.7550 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.66294\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1.6910 - accuracy: 0.0770 - val_loss: 1.7221 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.66294\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.6171 - accuracy: 0.2749 - val_loss: 1.8756 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.66294\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.7658 - accuracy: 0.2222\n",
      "Val Score:  [1.7658412456512451, 0.2222222238779068]\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  2\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 1.7278 - accuracy: 0.2222 - val_loss: 1.8859 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.66294\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.7228 - accuracy: 0.2222 - val_loss: 2.0501 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.66294\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 1.6268 - accuracy: 0.1944 - val_loss: 1.8207 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.66294\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.6606 - accuracy: 0.1944 - val_loss: 1.6321 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.66294 to 1.63207, saving model to face_detect_LeNet_Adam.h5\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 1.6424 - accuracy: 0.2222 - val_loss: 1.7328 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.63207\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 110ms/step - loss: 1.7045 - accuracy: 0.2222 - val_loss: 1.9900 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.63207\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.6677 - accuracy: 0.1667 - val_loss: 2.0185 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.63207\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.6494 - accuracy: 0.2222 - val_loss: 1.8214 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.63207\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.6484 - accuracy: 0.1667 - val_loss: 1.7150 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.63207\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.5663 - accuracy: 0.2222\n",
      "Val Score:  [1.5663495063781738, 0.2222222238779068]\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  3\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 93ms/step - loss: 1.6492 - accuracy: 0.1944 - val_loss: 1.6920 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.63207\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 1.6940 - accuracy: 0.2222 - val_loss: 1.4976 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.63207 to 1.49760, saving model to face_detect_LeNet_Adam.h5\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1.6769 - accuracy: 0.1944 - val_loss: 1.7313 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.49760\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1.6447 - accuracy: 0.1389 - val_loss: 1.7972 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.49760\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 1.6275 - accuracy: 0.2222 - val_loss: 1.6552 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.49760\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1.6662 - accuracy: 0.2222 - val_loss: 1.5232 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.49760\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1.6597 - accuracy: 0.1111 - val_loss: 1.6104 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.49760\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.7780 - accuracy: 0.2222\n",
      "Val Score:  [1.77804434299469, 0.2222222238779068]\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  4\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.7367 - accuracy: 0.1389 - val_loss: 1.6017 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49760\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.7865 - accuracy: 0.1667 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.49760\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 1.6872 - accuracy: 0.2222 - val_loss: 1.6795 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.49760\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 1.8280 - accuracy: 0.2222 - val_loss: 1.5818 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.49760\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1.6391 - accuracy: 0.1667 - val_loss: 1.8816 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.49760\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1.7061 - accuracy: 0.2500 - val_loss: 1.8075 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.49760\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 1.7810 - accuracy: 0.1944 - val_loss: 1.5015 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.49760\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 1.6968 - accuracy: 0.2222 - val_loss: 1.6478 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.49760\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 1.6375 - accuracy: 0.2500 - val_loss: 1.8536 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.49760\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 1.7143 - accuracy: 0.3056 - val_loss: 1.8498 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.49760\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 1.7327 - accuracy: 0.1944 - val_loss: 1.4952 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.49760 to 1.49519, saving model to face_detect_LeNet_Adam.h5\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 1.6999 - accuracy: 0.1944 - val_loss: 1.7268 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.49519\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 33ms/step - loss: 1.6734 - accuracy: 0.2500 - val_loss: 1.9550 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.49519\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1.6778 - accuracy: 0.1944 - val_loss: 1.7182 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.49519\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1.6747 - accuracy: 0.1111 - val_loss: 1.6171 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.49519\n",
      "Epoch 16/30\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1.6164 - accuracy: 0.2500 - val_loss: 1.7084 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.49519\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.7254 - accuracy: 0.1111\n",
      "Val Score:  [1.7254300117492676, 0.1111111119389534]\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  5\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.6719 - accuracy: 0.1944 - val_loss: 1.7576 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.49519\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1.7375 - accuracy: 0.1389 - val_loss: 1.9039 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.49519\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.7015 - accuracy: 0.1111 - val_loss: 1.6687 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.49519\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 1.6710 - accuracy: 0.1667 - val_loss: 1.6352 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.49519\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.6207 - accuracy: 0.1944 - val_loss: 1.8589 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.49519\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.6992 - accuracy: 0.1944 - val_loss: 1.8429 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.49519\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.6243 - accuracy: 0.1667 - val_loss: 1.5938 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.49519\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.6580 - accuracy: 0.1389 - val_loss: 1.6830 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.49519\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1.6468 - accuracy: 0.1389 - val_loss: 1.7197 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.49519\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1.7130 - accuracy: 0.1111 - val_loss: 1.6740 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.49519\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 1.6672 - accuracy: 0.2222 - val_loss: 1.8242 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.49519\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 1.6950 - accuracy: 0.1667 - val_loss: 1.6629 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.49519\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.6079 - accuracy: 0.2222\n",
      "Val Score:  [1.6079105138778687, 0.2222222238779068]\n",
      "====================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#save the model history in a list after fitting so that we can plot later\n",
    "LeNet_Adam_history = [] \n",
    "\n",
    "for i in range(n_folds):\n",
    "    print(\"Training on Fold: \",i+1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, \n",
    "                                               random_state = np.random.randint(1,500, 1)[0])\n",
    "    LeNet_Adam_history.append(fit_and_evaluate(LeNet_Adam, x_train, X_valid, x_test,\n",
    "                                              y_train, Y_valid, y_test, LeNet_Adam_model_checkpoint))\n",
    "    print(\"=======\"*12, end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-medicine",
   "metadata": {},
   "source": [
    "Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "extreme-market",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Fold:  1\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 1s 85ms/step - loss: 1.7463 - accuracy: 0.2164 - val_loss: 2.2264 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.22639, saving model to face_detect_LeNet_Adagrad.h5\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 1.6383 - accuracy: 0.3119 - val_loss: 1.7422 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.22639 to 1.74219, saving model to face_detect_LeNet_Adagrad.h5\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.5318 - accuracy: 0.1794 - val_loss: 1.7218 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.74219 to 1.72178, saving model to face_detect_LeNet_Adagrad.h5\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1.4385 - accuracy: 0.5729 - val_loss: 1.7793 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.72178\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1.3277 - accuracy: 0.5492 - val_loss: 1.5729 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.72178 to 1.57293, saving model to face_detect_LeNet_Adagrad.h5\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 1.2215 - accuracy: 0.8171 - val_loss: 1.6249 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.57293\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 1.0382 - accuracy: 0.7703 - val_loss: 1.5773 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.57293\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.8501 - accuracy: 0.9184 - val_loss: 1.8749 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.57293\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.6719 - accuracy: 0.8536 - val_loss: 1.3505 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.57293 to 1.35048, saving model to face_detect_LeNet_Adagrad.h5\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.6757 - accuracy: 0.9473 - val_loss: 1.4973 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.35048\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.6394 - accuracy: 0.7159 - val_loss: 1.4855 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.35048\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.3748 - accuracy: 1.0000 - val_loss: 1.8097 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.35048\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 0.2843 - accuracy: 0.9473 - val_loss: 1.2559 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.35048 to 1.25594, saving model to face_detect_LeNet_Adagrad.h5\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.2375 - accuracy: 1.0000 - val_loss: 1.4764 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.25594\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.1763 - accuracy: 1.0000 - val_loss: 1.2257 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.25594 to 1.22567, saving model to face_detect_LeNet_Adagrad.h5\n",
      "Epoch 16/30\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.1327 - accuracy: 1.0000 - val_loss: 1.2267 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.22567\n",
      "Epoch 17/30\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.1319 - accuracy: 1.0000 - val_loss: 1.1850 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.22567 to 1.18497, saving model to face_detect_LeNet_Adagrad.h5\n",
      "Epoch 18/30\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.0979 - accuracy: 1.0000 - val_loss: 1.2172 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.18497\n",
      "Epoch 19/30\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0864 - accuracy: 1.0000 - val_loss: 1.1206 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.18497 to 1.12059, saving model to face_detect_LeNet_Adagrad.h5\n",
      "Epoch 20/30\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0701 - accuracy: 1.0000 - val_loss: 1.2377 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.12059\n",
      "Epoch 21/30\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 1.2183 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.12059\n",
      "Epoch 22/30\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 1.2909 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.12059\n",
      "Epoch 23/30\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0533 - accuracy: 1.0000 - val_loss: 1.2599 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.12059\n",
      "Epoch 24/30\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 1.1906 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.12059\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2124 - accuracy: 0.5556\n",
      "Val Score:  [1.2124378681182861, 0.5555555820465088]\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  2\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.4561 - accuracy: 0.8611 - val_loss: 1.0347 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.12059 to 1.03470, saving model to face_detect_LeNet_Adagrad.h5\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.2064 - accuracy: 0.9444 - val_loss: 1.3201 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.03470\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.1178 - accuracy: 1.0000 - val_loss: 1.1696 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.03470\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0820 - accuracy: 1.0000 - val_loss: 0.9707 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.03470 to 0.97068, saving model to face_detect_LeNet_Adagrad.h5\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0708 - accuracy: 1.0000 - val_loss: 1.3197 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.97068\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 1.1897 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.97068\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0507 - accuracy: 1.0000 - val_loss: 1.3408 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.97068\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 1.2228 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.97068\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 1.3068 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.97068\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0589 - accuracy: 1.0000\n",
      "Val Score:  [0.05886777117848396, 1.0]\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  3\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.0790 - accuracy: 1.0000 - val_loss: 0.9856 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.97068\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 1.1730 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.97068\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 1.1055 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.97068\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 1.0192 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.97068\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 1.0725 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.97068\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 1.0982 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.97068\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0441 - accuracy: 1.0000\n",
      "Val Score:  [0.044140852987766266, 1.0]\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  4\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 1.1131 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.97068\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 1.0497 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.97068\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 1.0728 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.97068\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 1.1496 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.97068\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.9995 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.97068\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 1.0059 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.97068\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 1.0455 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.97068\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.9750 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.97068\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 1.1166 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.97068\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 1.0768 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.97068\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 1.0574 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.97068\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 1.0174 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.97068\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 1.0417 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.97068\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0459 - accuracy: 1.0000\n",
      "Val Score:  [0.0459078811109066, 1.0]\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  5\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 1.0606 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.97068\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 1.0985 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.97068\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 1.1200 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.97068\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 1.1340 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.97068\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 1.0971 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.97068\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 1.0914 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.97068\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0336 - accuracy: 1.0000\n",
      "Val Score:  [0.03355986624956131, 1.0]\n",
      "====================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#save the model history in a list after fitting so that we can plot later\n",
    "LeNet_Adagrad_history = [] \n",
    "\n",
    "for i in range(n_folds):\n",
    "    print(\"Training on Fold: \",i+1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, \n",
    "                                               random_state = np.random.randint(1,500, 1)[0])\n",
    "    LeNet_Adagrad_history.append(fit_and_evaluate(LeNet_Adagrad, x_train, X_valid, x_test,\n",
    "                                              y_train, Y_valid, y_test, LeNet_Adagrad_model_checkpoint))\n",
    "    print(\"=======\"*12, end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-seating",
   "metadata": {},
   "source": [
    "Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "closing-nicholas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Fold:  1\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 1s 97ms/step - loss: 1.6335 - accuracy: 0.2199 - val_loss: 1.6681 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.66812, saving model to face_detect_LeNet_Adadelta.h5\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1.6073 - accuracy: 0.1869 - val_loss: 1.6561 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.66812 to 1.65610, saving model to face_detect_LeNet_Adadelta.h5\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 1.5837 - accuracy: 0.2506 - val_loss: 1.6426 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.65610 to 1.64263, saving model to face_detect_LeNet_Adadelta.h5\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1.5888 - accuracy: 0.2975 - val_loss: 1.6506 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.64263\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 1.5763 - accuracy: 0.3189 - val_loss: 1.6704 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.64263\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 1.5542 - accuracy: 0.2662 - val_loss: 1.6549 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.64263\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 1.5707 - accuracy: 0.3200 - val_loss: 1.7062 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.64263\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 1.5635 - accuracy: 0.2188 - val_loss: 1.7186 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.64263\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5449 - accuracy: 0.5556\n",
      "Val Score:  [1.544857382774353, 0.5555555820465088]\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  2\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.5678 - accuracy: 0.3056 - val_loss: 1.6649 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.64263\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 1.5489 - accuracy: 0.2778 - val_loss: 1.6758 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.64263\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 94ms/step - loss: 1.5337 - accuracy: 0.3611 - val_loss: 1.6997 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.64263\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 1.5186 - accuracy: 0.3611 - val_loss: 1.6957 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.64263\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 1.5105 - accuracy: 0.2778 - val_loss: 1.6896 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.64263\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 1.5085 - accuracy: 0.3611 - val_loss: 1.7013 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.64263\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.6881 - accuracy: 0.0000e+00\n",
      "Val Score:  [1.6881247758865356, 0.0]\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  3\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 1.5729 - accuracy: 0.2500 - val_loss: 1.6338 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00001: val_loss improved from 1.64263 to 1.63379, saving model to face_detect_LeNet_Adadelta.h5\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 1.5509 - accuracy: 0.3056 - val_loss: 1.6244 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.63379 to 1.62442, saving model to face_detect_LeNet_Adadelta.h5\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 1.5554 - accuracy: 0.3889 - val_loss: 1.5850 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.62442 to 1.58496, saving model to face_detect_LeNet_Adadelta.h5\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.5334 - accuracy: 0.3889 - val_loss: 1.5618 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.58496 to 1.56178, saving model to face_detect_LeNet_Adadelta.h5\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.5265 - accuracy: 0.4167 - val_loss: 1.5510 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.56178 to 1.55104, saving model to face_detect_LeNet_Adadelta.h5\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.5261 - accuracy: 0.3889 - val_loss: 1.5650 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.55104\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 1.5033 - accuracy: 0.4167 - val_loss: 1.5521 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.55104\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 1.5027 - accuracy: 0.4167 - val_loss: 1.5711 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.55104\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 1.4890 - accuracy: 0.3889 - val_loss: 1.5461 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.55104 to 1.54614, saving model to face_detect_LeNet_Adadelta.h5\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.4796 - accuracy: 0.5556 - val_loss: 1.5418 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.54614 to 1.54176, saving model to face_detect_LeNet_Adadelta.h5\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.4738 - accuracy: 0.5000 - val_loss: 1.5658 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.54176\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 1.4585 - accuracy: 0.4722 - val_loss: 1.5729 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.54176\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 1.4476 - accuracy: 0.4444 - val_loss: 1.5434 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.54176\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 1.4440 - accuracy: 0.5278 - val_loss: 1.5651 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.54176\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 1.4352 - accuracy: 0.5000 - val_loss: 1.5692 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.54176\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.6843 - accuracy: 0.0000e+00\n",
      "Val Score:  [1.6843147277832031, 0.0]\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  4\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 62ms/step - loss: 1.5044 - accuracy: 0.4444 - val_loss: 1.6090 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.54176\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1.4729 - accuracy: 0.6111 - val_loss: 1.6168 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.54176\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.4548 - accuracy: 0.6667 - val_loss: 1.6620 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.54176\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 1.4411 - accuracy: 0.5833 - val_loss: 1.7026 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.54176\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.4424 - accuracy: 0.4167 - val_loss: 1.6922 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.54176\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 1.4275 - accuracy: 0.5000 - val_loss: 1.6770 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.54176\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5571 - accuracy: 0.2222\n",
      "Val Score:  [1.5570964813232422, 0.2222222238779068]\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 1.4974 - accuracy: 0.5833 - val_loss: 1.5704 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.54176\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.4863 - accuracy: 0.5556 - val_loss: 1.5625 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.54176\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.4729 - accuracy: 0.4167 - val_loss: 1.5799 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.54176\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1.4641 - accuracy: 0.6111 - val_loss: 1.6122 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.54176\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1.4513 - accuracy: 0.7500 - val_loss: 1.6097 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.54176\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 1.4471 - accuracy: 0.7222 - val_loss: 1.5946 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.54176\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1.4457 - accuracy: 0.6389 - val_loss: 1.6138 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.54176\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.4958 - accuracy: 0.4444\n",
      "Val Score:  [1.4957869052886963, 0.4444444477558136]\n",
      "====================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#save the model history in a list after fitting so that we can plot later\n",
    "LeNet_Adadelta_history = [] \n",
    "\n",
    "for i in range(n_folds):\n",
    "    print(\"Training on Fold: \",i+1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, \n",
    "                                               random_state = np.random.randint(1,500, 1)[0])\n",
    "    LeNet_Adadelta_history.append(fit_and_evaluate(LeNet_Adadelta, x_train, X_valid, x_test,\n",
    "                                              y_train, Y_valid, y_test, LeNet_Adadelta_model_checkpoint))\n",
    "    print(\"=======\"*12, end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-reason",
   "metadata": {},
   "source": [
    "Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "spectacular-haven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Fold:  1\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 2s 97ms/step - loss: 2.9651 - accuracy: 0.3194 - val_loss: 2.8361 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.83613, saving model to face_detect_LeNet_Nadam.h5\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 2.3897 - accuracy: 0.2141 - val_loss: 1.9100 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.83613 to 1.90999, saving model to face_detect_LeNet_Nadam.h5\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 1.9305 - accuracy: 0.1563 - val_loss: 1.9366 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.90999\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1.9092 - accuracy: 0.1510 - val_loss: 1.7676 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.90999 to 1.76762, saving model to face_detect_LeNet_Nadam.h5\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1.8372 - accuracy: 0.0839 - val_loss: 1.7343 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.76762 to 1.73425, saving model to face_detect_LeNet_Nadam.h5\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 1.7829 - accuracy: 0.1840 - val_loss: 1.7833 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.73425\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 1.6684 - accuracy: 0.2367 - val_loss: 1.5540 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.73425 to 1.55398, saving model to face_detect_LeNet_Nadam.h5\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 1.7310 - accuracy: 0.1522 - val_loss: 1.5530 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.55398 to 1.55296, saving model to face_detect_LeNet_Nadam.h5\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 2.0119 - accuracy: 0.0521 - val_loss: 1.8606 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.55296\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.7905 - accuracy: 0.1412 - val_loss: 1.5991 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.55296\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 0s 90ms/step - loss: 1.7105 - accuracy: 0.1609 - val_loss: 1.6921 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.55296\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 1.7147 - accuracy: 0.1059 - val_loss: 1.9180 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.55296\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.7818 - accuracy: 0.1759 - val_loss: 1.7886 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.55296\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.9985 - accuracy: 0.1111\n",
      "Val Score:  [1.9985451698303223, 0.1111111119389534]\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  2\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 1.7317 - accuracy: 0.1944 - val_loss: 1.8139 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.55296\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 1.7251 - accuracy: 0.1667 - val_loss: 1.5174 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.55296 to 1.51736, saving model to face_detect_LeNet_Nadam.h5\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 1s 88ms/step - loss: 1.6982 - accuracy: 0.2500 - val_loss: 1.8148 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.51736\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.7060 - accuracy: 0.2778 - val_loss: 1.8523 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.51736\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.7044 - accuracy: 0.2222 - val_loss: 2.0461 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.51736\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 1.7040 - accuracy: 0.2222 - val_loss: 2.2097 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.51736\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 1.8882 - accuracy: 0.1111 - val_loss: 1.8169 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.51736\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.4499 - accuracy: 0.3333\n",
      "Val Score:  [1.449863314628601, 0.3333333432674408]\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  3\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 1.9212 - accuracy: 0.1111 - val_loss: 1.7432 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51736\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.6823 - accuracy: 0.1944 - val_loss: 2.0131 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.51736\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 1.6721 - accuracy: 0.1389 - val_loss: 1.5425 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.51736\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1.7107 - accuracy: 0.2222 - val_loss: 1.6331 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.51736\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 1.7253 - accuracy: 0.1667 - val_loss: 1.8234 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.51736\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 1.6770 - accuracy: 0.2222 - val_loss: 1.9087 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.51736\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1.7409 - accuracy: 0.1111 - val_loss: 1.7511 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.51736\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 1.6899 - accuracy: 0.1667 - val_loss: 1.8816 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.51736\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2.1274 - accuracy: 0.1111\n",
      "Val Score:  [2.127384901046753, 0.1111111119389534]\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  4\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 1.8453 - accuracy: 0.1667 - val_loss: 1.5782 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51736\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 1.7356 - accuracy: 0.1667 - val_loss: 1.6586 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.51736\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 1.7795 - accuracy: 0.1667 - val_loss: 2.1352 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.51736\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 1.7773 - accuracy: 0.2500 - val_loss: 2.0104 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.51736\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 1.7009 - accuracy: 0.2222 - val_loss: 1.5306 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.51736\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.8250 - accuracy: 0.0833 - val_loss: 1.9121 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.51736\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 1.7549 - accuracy: 0.1111 - val_loss: 1.8477 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.51736\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.8177 - accuracy: 0.0556 - val_loss: 1.7686 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.51736\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.8168 - accuracy: 0.0556 - val_loss: 1.7804 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.51736\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 56ms/step - loss: 1.7653 - accuracy: 0.1111 - val_loss: 2.1992 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.51736\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.7392 - accuracy: 0.1111\n",
      "Val Score:  [1.7392021417617798, 0.1111111119389534]\n",
      "====================================================================================\n",
      "\n",
      "\n",
      "Training on Fold:  5\n",
      "Epoch 1/30\n",
      "5/5 [==============================] - 0s 100ms/step - loss: 1.7410 - accuracy: 0.1111 - val_loss: 2.0298 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 1.51736\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.7734 - accuracy: 0.1667 - val_loss: 1.9725 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.51736\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 1.7058 - accuracy: 0.2222 - val_loss: 2.0354 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.51736\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 1.7399 - accuracy: 0.2222 - val_loss: 1.5760 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.51736\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 1.7076 - accuracy: 0.1944 - val_loss: 1.8061 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.51736\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.6986 - accuracy: 0.2222 - val_loss: 1.7839 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.51736\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 1.7652 - accuracy: 0.1667 - val_loss: 1.7125 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.51736\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1.9176 - accuracy: 0.1944 - val_loss: 1.5617 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.51736\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 1.7958 - accuracy: 0.0833 - val_loss: 1.5424 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.51736\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 0s 68ms/step - loss: 1.6881 - accuracy: 0.2222 - val_loss: 1.8150 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.51736\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 1.8141 - accuracy: 0.1944 - val_loss: 1.7904 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.51736\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 1s 141ms/step - loss: 1.6544 - accuracy: 0.1944 - val_loss: 2.0188 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.51736\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 1.6813 - accuracy: 0.2222 - val_loss: 1.6266 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.51736\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 1.6446 - accuracy: 0.2222 - val_loss: 1.8891 - val_accuracy: 0.2000\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.51736\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 1.6833 - accuracy: 0.0000e+00\n",
      "Val Score:  [1.6832672357559204, 0.0]\n",
      "====================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#save the model history in a list after fitting so that we can plot later\n",
    "LeNet_Nadam_history = [] \n",
    "\n",
    "for i in range(n_folds):\n",
    "    print(\"Training on Fold: \",i+1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, \n",
    "                                               random_state = np.random.randint(1,500, 1)[0])\n",
    "    LeNet_Nadam_history.append(fit_and_evaluate(LeNet_Nadam, x_train, X_valid, x_test,\n",
    "                                              y_train, Y_valid, y_test, LeNet_Nadam_model_checkpoint))\n",
    "    print(\"=======\"*12, end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-aviation",
   "metadata": {},
   "source": [
    "## Model Evaluation - Accuracy and predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-spiritual",
   "metadata": {},
   "source": [
    "Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "solar-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_SGD = load_model('face_detect_LeNet_SGD.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "rubber-facing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 203ms/step - loss: 0.2463 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24631139636039734, 1.0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score trained model.\n",
    "model_SGD.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "perfect-harrison",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0774 - accuracy: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.07744300365448, 0.4000000059604645]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score trained model.\n",
    "model_SGD.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dangerous-solomon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions.\n",
    "pred_SGD = model_SGD.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-jerusalem",
   "metadata": {},
   "source": [
    "Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "smart-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Adam = load_model('face_detect_LeNet_Adam.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "intended-hudson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 244ms/step - loss: 1.6244 - accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6243746280670166, 0.3333333432674408]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score trained model.\n",
    "model_Adam.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "favorite-imperial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 1.4952 - accuracy: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4951941967010498, 0.4000000059604645]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score trained model.\n",
    "model_Adam.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "constitutional-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions.\n",
    "pred_Adam = model_Adam.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-picking",
   "metadata": {},
   "source": [
    "Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fitted-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Adadelta = load_model('face_detect_LeNet_Adadelta.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "undefined-officer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 154ms/step - loss: 1.5012 - accuracy: 0.4444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5011972188949585, 0.4444444477558136]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score trained model.\n",
    "model_Adadelta.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "photographic-plaza",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step - loss: 1.5418 - accuracy: 0.2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5417613983154297, 0.20000000298023224]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score trained model.\n",
    "model_Adadelta.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "green-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions.\n",
    "pred_Adadelta = model_Adadelta.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-stations",
   "metadata": {},
   "source": [
    "Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "configured-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Nadam = load_model('face_detect_LeNet_Nadam.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "naval-dutch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 64 calls to <function Model.make_test_function.<locals>.test_function at 0x1a42863c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 1.4875 - accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4875410795211792, 0.3333333432674408]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score trained model.\n",
    "model_Nadam.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "arranged-arnold",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5174 - accuracy: 0.2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5173606872558594, 0.20000000298023224]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score trained model.\n",
    "model_Nadam.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "incident-resolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions.\n",
    "pred_Nadam = model_Nadam.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-local",
   "metadata": {},
   "source": [
    "Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "metallic-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Adagrad = load_model('face_detect_LeNet_Adagrad.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "induced-pregnancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 66 calls to <function Model.make_test_function.<locals>.test_function at 0x1a66afc730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0539 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.053869955241680145, 1.0]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score trained model.\n",
    "model_Adagrad.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "economic-premium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step - loss: 0.9707 - accuracy: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9706772565841675, 0.6000000238418579]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score trained model.\n",
    "model_Adagrad.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "median-magnet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1a667ca730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# make predictions.\n",
    "pred_Adagrad = model_Adagrad.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-malawi",
   "metadata": {},
   "source": [
    "## Model Evaluation - model accuracy/loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "polar-graphics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Accuracies vs Epochs (LeNet+Adagrad)')\n",
    "plt.plot(LeNet_SGD_history[0].history['accuracy'], label='Training Fold 1')\n",
    "plt.plot(LeNet_SGD_history[1].history['accuracy'], label='Training Fold 2')\n",
    "plt.plot(LeNet_SGD_history[2].history['accuracy'], label='Training Fold 3')\n",
    "plt.plot(LeNet_SGD_history[3].history['accuracy'], label='Training Fold 4')\n",
    "plt.plot(LeNet_SGD_history[4].history['accuracy'], label='Training Fold 5')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "accessory-tamil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABLdklEQVR4nO3dd3xV9fnA8c+TvXfIJAkzgz0EZAmCiuJqlbqrtdZRR2tbV1uttdra2p+r1jpqq1arrbhwVAVlCspGw0ogrIQEsvfO9/fHOQk3IQkBQu5N8rxfr/PKvWc+997c53zv95zzHDHGoJRSqu9yc3YASimlTi1N9Eop1cdpoldKqT5OE71SSvVxmuiVUqqP00SvlFJ9nCZ61eeIyHUisqqb1pUmIutFRLpjfb2BiOwVkbnOjgNARF4WkYftx6NFZLWzY+qNNNH3Aq70xTteIjJLRJpEpKLNcLqzY+ui3wF/NvYFJyfyWYhIkogYEfm4zfjXROTBLq7jpP4HRCTAft//d6LrcDZjzDdAiYhc4OxYehtN9KonHDTGBLQZ1jg7qGMRkRhgNvBeN61ysohM7aZ1tSIiy0RkViezXALUAmeJSPSpiOFYRMSjG1bzOnBTN6ynX9FE34uJiLeIPCkiB+3hSRHxtqdFiMiHIlIiIkUislJE3Oxp94hIjoiUi8hOEZnTzroni0ieiLg7jPuOiHxjP55kd2mUicghEXn8BF/DMhH5g4istdf1voiEOUy/UES22q9jmYikOkwbKCLviEi+iBSKyDNt1v1nESkWkT0icq7D+OtEJMt+/XtE5KoOwjsL2GiMqenC63ATkXtFZLcdy38dX4ftT8AjnazjfBHZbL/W1SIy2h7/LyAB+MBuld99rHjacS3wHPANcHWb7V4jIvvsuH/VZtokEVljx5QrIs+IiJfD9LPt/6FSEXlWRJaLyA32tOtE5EsReUJECoEHRWSIiHxhb6tARF4XkRCH9Y0TkY32Z/MfwKfN61gGzGn+P1ddZIzRwcUHYC8wt53xDwFfAQOASGA18Dt72h+wvtie9jADECAZOADE2vMlAUM62O5u4CyH528B99qP1wDX2I8DgCkdrGMWkN3Ja1sG5AAjAX/gbeA1e9pwoBIr4XoCdwO7AC/AHdgCPGEv5wNMt5e7DqgHfmTPdwtw0H79/kAZkGzPGwOM6CC2x4C/dvGz+In9WcQD3sDzwBsO77EBAu3XOtce/xrwoP14HHAYmGzHfK29Le/OttvmfZzVwbREoAlIA34OfOMwLQ2oAGbacT8ONDjEOAGYAnjYr2M78FN7WoT9Xn7Xnv4T+32/weFzaABut6f7AkPtz9Mb6392BfCkPb8XsA+40/68L7XX93Cb11MGjHb297I3DU4PQIcufEgdJ5fdwHkOz88B9tqPHwLeB4a2WWaonVDmAp7H2O7DwD/sx4FYSTfRfr4C+C0QcYx1zLKTTEmbwd+evgx41GH+NKDOTnb3A/91mOaGlShnAacD+YBHO9u8Dtjl8NwPK9FGYyX6EqyuDN9jxP6iY2zH+Cy2A3McnsfYSao5QRr78Y+Br+x5HBP937B30g7r2Amc0dl2HeZdRseJ/tfAZvtxHNAIjLOfPwC86TCvv/3+t7st4KfAu/bj7wNrHKYJViPCMdHvP8Z7fDGwyX48E3uH7DB9NUcn+hxgZk9/D3vzoF03vVssVguo2T57HFit0V3AZ3Y3xb0AxphdWF/WB4HDIvKmiMTSvn8D37V/Jn8XqxujeXs/xGpx7xCRdSJyfidxHjTGhLQZKh2mH2jzGjyxWoutXp8xpsmeNw4YCOwzxjR0sM08h+Wq7IcB9nYvA24GckXkIxFJ6WAdxVg7uK5IBN61uzhKsBJ/IxDVZr6/A1HtHFBMBH7evLy9joEc+TyP0mbe6cCHDuPudZj1+1h92xhjcoDlWL8YsNff8v7b70+hwzaG212AeSJSBvwe67Npb1kDZLcJ0/GzRUSi7P+5HHt9r7VZX469nmaO/9/NArF21qqLNNH3bgexEkSzBHscxphyY8zPjTGDgQuBnzX3xRtj/m2MmW4va4A/trdyY8w2rC/aucCVWIm/eVqmMeYKrG6jPwILRcT/BF/HwDavoR4oaPv6RETseXOwEkiCnMABPmPMp8aYs7Ba3TuwWu7t+QZrZ9YVB4Bz2+zMfOzE6rjtOqxfQr/DagE7Lv9Im+X9jDFvNC/azutomRdYBZzvMO5RALEO/g4D7rOTdR5W99CV9nuXi8P7LyJ+QLjDZv6G9R4NM8YEAb90iDsXq6uqeVlxfN5B3L+3x42y13d1m/XF2etpluC4sIjEYXXx7Gz7fqiOaaLvPTxFxMdh8ADeAH4tIpEiEoH1M/w1aDmwN9T+0pRitS6bRCRZRM60W+k1QDVW10pH/o3V9zoTq48ee/1Xi0ik3cousUd3tp7OXC3W+ep+WF1OC40xjcB/gfkiMkdEPLH6l2uxfs6vxUoMj4qIv/2eTDvWhuwW5UX2TqkWq3+6o7gXA+NFpO0BwfY+i+eAR0Qk0d5OpIhc1MF6/4V1TGGew7gXgZvFOggu9muaLyLNvygOAYOP9fraca39OtKAsfYwEqu//FxgIXC+iEy3D7I+ROu8EIjVJ15h//K5xWHaR8AoEbnYfg9uxeoe60wg1nteaiftuxymrcHq079DRDxF5LvApDbLnwF8YYyp7cJrV82c3Xekw7EHrP5Z02Z4GCtZPI2V8HLtxz72Mnfay1Vi/Zy+3x4/GitJlgNFwIfYB2Y72HYCViL8qM3417D6+iuArcDFHSw/y16+os1wiT19GdaB47VYCeUDHPr9ge8A27B2VstxOHBqx/YeVldDAfC0Pf46YFWbOAzW8YkYez2lWDuoZUBaJ6//LeCyLnwWbsDPsFqa5VjHT35vL5Nkz+fhsJ7v2eMedBg3D1hnx5VrbzvQnnYRsN+e9ot24lxGmz56+/+jGLignfmfxdqhgrUz2G+/j7/C4XgA1g5+h/2ZrcTaEaxqE3OG/X4+S+uD9O19DiOADfb6NmPtvLMdpk8ENtnv4X/s4WGH6R8BFzr7O9nbBrHfPKWcQkSWYZ1l83dnx9IeEUkDXgEmGf2ydEqs03ezgauMMUtPwfpHA88bY3rLxXYuQ7tulOqEMWabMeY0TfLtE5FzRCTE7gps7r//6lRsyxjzjSb5E6OJXil1Mk7H6qYqAC7A6sKrdm5Iqi3tulFKqT5OW/RKKdXHdUeRoW4XERFhkpKSnB2GUkr1Ghs2bCgwxkS2N80lE31SUhLr1693dhhKKdVriEh7VxED2nWjlFJ9niZ6pZTq4zTRK6VUH+eSffRKqZ5VX19PdnY2NTXHvMeKcjIfHx/i4+Px9PTs8jKa6JVSZGdnExgYSFJSEtJ/7oPe6xhjKCwsJDs7m0GDBnV5Oe26UUpRU1NDeHi4JnkXJyKEh4cf9y8vTfRKKQBN8r3EiXxOfSbRG2N45otM0nNKnR2KUkq5lD6T6Eur6/n31/v54SvryCvVA0pK9RaFhYWMHTuWsWPHEh0dTVxcXMvzurq6Tpddv349d9xxxzG3MXXq1G6JddmyZQQHB7fEN3fu3E7nT0pKoqCg4KjxDz74IH/+85+PGr9ixQrGjx+Ph4cHCxcu7JaYoQ8djA3x8+Kl605jwXNr+OEr6/jvTafj791nXp5SfVZ4eDibN28GrAQYEBDAL37xi5bpDQ0NeHi0/12eOHEiEydOPOY2Vq9e3S2xAsyYMYMPP/yw29bnKCEhgZdffrndncDJ6DMteoDUmCD+cuU4tueW8ZM3N9HYpJU5leqNrrvuOm6++WYmT57M3Xffzdq1azn99NMZN24cU6dOZedO65axy5Yt4/zzrfvSP/jgg1x//fXMmjWLwYMH8/TTT7esLyAgoGX+WbNmcemll5KSksJVV13VfOcqPv74Y1JSUpgwYQJ33HFHy3q74o033mDUqFGMHDmSe+65p915HnnkEYYPH8706dNb4m8rKSmJ0aNH4+bWvam5zzV5ZycP4LcXjuD+97fyyEfbeeCCNGeHpFSv8tsPtrLtYFm3rjMtNojfXDDiuJbJzs5m9erVuLu7U1ZWxsqVK/Hw8GDJkiX88pe/5O233z5qmR07drB06VLKy8tJTk7mlltuOep8802bNrF161ZiY2OZNm0aX375JRMnTuSmm25ixYoVDBo0iCuuuKLDuFauXMnYsWMBWLBgAT/4wQ+455572LBhA6GhoZx99tm89957XHzxxS3LbNiwgTfffJPNmzfT0NDA+PHjmTBhwnG9HyejzyV6gGtOTyKroJJ/fLmHQRF+XHN6krNDUkodpwULFuDu7g5AaWkp1157LZmZmYgI9fX17S4zf/58vL298fb2ZsCAARw6dIj4+PhW80yaNKll3NixY9m7dy8BAQEMHjy45dz0K664ghdeeKHdbbTtunn//feZNWsWkZFW4cirrrqKFStWtEr0K1eu5Dvf+Q5+fn4AXHjhhSfwjpy4PpnoAX49P40DRVX8ZtFW4sP8mJ08wNkhKdUrHG/L+1Tx9/dveXz//fcze/Zs3n33Xfbu3cusWbPaXcbb27vlsbu7Ow0NDSc0T1/Tp/roHbm7CU9dPo7UmCBue30j23O796eoUqrnlJaWEhcXB8DLL7/c7etPTk4mKyuLvXv3AvCf//yny8tOmjSJ5cuXU1BQQGNjI2+88QZnnHFGq3lmzpzJe++9R3V1NeXl5XzwwQfdGf4x9dlED+Dv7cFL155GgI8HP3x5HYfL9LRLpXqju+++m/vuu49x48adkha4r68vzz77LPPmzWPChAkEBgYSHBzcpWVjYmJ49NFHmT17NmPGjGHChAlcdNFFreYZP348l112GWPGjOHcc8/ltNNOa3dd69atIz4+nrfeeoubbrqJESO659eVS94zduLEiaY7bzySnlPK955fw9ABAbx54xT8vPpsj5VSJ2T79u2kpqY6OwynqqioICAgAGMMt956K8OGDePOO+90dljtau/zEpENxph2zzXt0y36ZiPjgnn68nGk55Ry538206SnXSql2njxxRcZO3YsI0aMoLS0lJtuusnZIXWbfpHoAeamRfHr+Wl8uvUQf/xkh7PDUUq5mDvvvJPNmzezbds2Xn/99ZYzZPqCftWH8YNpSewtrOT5FVkkRfhzxaQEZ4eklFKnXL9K9CLCA+ensb+oil+/l058qC8zhrV703SllOoz+k3XTTMPdzf+csU4hg0I4MevbSTzULmzQ1JKqVOq3yV6gEAfT1667jR8vNz5wcvryC+vdXZISil1yhwz0YvIP0TksIikdzD9LhHZbA/pItIoImH2tL0i8q09rfvOl+wGcSG+vHTtRAoqavnRq+upqW90dkhK9UtapviIxx9/nLS0NEaPHs2cOXPYt29ft8TdlT76l4FngFfbm2iMeQx4DEBELgDuNMYUOcwy2xhz9Ct1AaPjQ3jq8nHc/NoGfv7fLfzlinG4uelddpTqSVqm+Ihx48axfv16/Pz8+Nvf/sbdd999XFfpduSYLXpjzAqg6Fjz2a4A3jipiHrYOSOiue/cFD76Npf/W9x+6VClVM/qr2WKZ8+e3XJa55QpU8jOzu5yDJ3ptrNuRMQPmAfc5jDaAJ+JiAGeN8a0Xw7OyX40YzB7Cqr469LdJIb7872JA50dklLO8797Ie/b7l1n9Cg499HjWqS/lyl+6aWXOPfcc7v+hnWiO0+vvAD4sk23zXRjTI6IDAAWi8gO+xfCUUTkRuBGsO6y0pNEhIcuGkF2cRW/fOdb4kN9mTokokdjUEq11p/LFL/22musX7+e5cuXdzpfV3Vnor+cNt02xpgc++9hEXkXmAS0m+jt1v4LYNW66ca4usTT3Y2/XjWeS55dzc3/2sA7P57G0AEBPR2GUs53nC3vU6W/lilesmQJjzzyCMuXL28V68noltMrRSQYOAN432Gcv4gENj8GzgbaPXPHVQT5ePKP607Dy8ON619eR1Fl50f8lVI9o7+UKd60aRM33XQTixYtYsCA7ruHRldOr3wDWAMki0i2iPxQRG4WkZsdZvsO8JkxptJhXBSwSkS2AGuBj4wxn3Rb5KfIwDA/Xvz+RA6V1XCjnnaplEvoL2WK77rrLioqKliwYAFjx47ttjtR9YsyxSfi429z+fHrG7lobCxPXjYWET3tUvVdWqZYyxT3S+eNiuHuecm8v/kgTyzJdHY4SqlTrC+XKe5XRc2O1y1nDGFvQSVPf57Jzrwybps9jFHxXfs5p5TqXe68806XbcGfLE30nRARHr54FDHBvvzzyz18uvUQZwyP5PYzhzIxKczZ4SmlVJdo180xeHm4cedZw/ny3jO5e14y6TmlXPrcGi5/YQ2rMgtwxWMcSinlSBN9FwX6ePLjWUNZdc+ZPHB+GnsKKrn6pa/5zrOrWbLtkCZ8pZTL0kR/nHy93Ll++iBW3D2b339nFIWVtdzw6nrOe3oVH35zkEa9H61SysVooj9B3h7uXDk5gaU/n8Xj3xtDXUMjt/17E2c9sZyFG7Kpb2xydohK9QpapviI5557jlGjRjF27FimT5/Otm3buiVuPRh7kjzc3fju+HguGhvHJ+l5PLN0F794awtPLsng5jOGsGBiPN4e7s4OUymXpWWKj7jyyiu5+WbrWtRFixbxs5/9jE8+OfnrTLVF303c3YT5o2P4+I7pvHTtRCICvPn1e+nM/NNS/r4yi6o616qnoZQr669lioOCgloeV1ZWdtuFmtqi72YiwpzUKM5MGcDq3YU888UuHv5oO88u280Ppw/imtMTCfLxPPaKlHKSP679IzuKdnTrOlPCUrhnUvsJsCP9tUzxX//6Vx5//HHq6ur44osvjus964i26E8REWHa0AjeuHEKb99yOmPig3ns051Me/QLHv9sJ8VaME2pTrUtU7xgwQJGjhzJnXfeydatW9tdprlMcUREREuZ4raayxS7ubm1lCnesWPHUWWKOzJjxgw2b97M5s2b+dWvfsW6detayhR7eHi0lCl25FimOCgoqNMaNrfeeiu7d+/mj3/8Iw8//PAx36eu0BZ9D5iQGMY/fzCJ9JxS/rp0F09/sYu/r9rDZacNZP6oGMYlhOKutzBULuJ4W96nSn8tU9zs8ssv55ZbbumWdWmLvgeNjAvmb1dPYPGdMzk7LYp/rdnHpc+tYdIjS7jrrS18ujVP+/KVakd/KVOcmXmkrtZHH33EsGHDjv/FtENb9E4wLCqQJy8fx0MXj2T5znwWbzvEJ1vzeGtDNt4ebkwfGsFZaVGcmTqAAYE+zg5XKae7++67ufbaa3n44YeZP39+t6/fsUyxv79/h2WE2+NYptgYw/z58zstUzxgwIAO1//MM8+wZMkSPD09CQ0N5ZVXXjmp19VMyxS7iPrGJtbuKWLxtkMs3naInJJqRGDswBDmpkZxdloUQwcEaLlkdUpomeK+XaZYW/QuwtPdjWlDI5g2NILfXJDGjrxyFm87xJLth3js05089ulOEsP9mJsaxVlpUUxMDMXDXXvelOouL774Iq+88gp1dXWMGzeuT5Up1hZ9L5BXWsOS7VbSX72rkLrGJkL8PDkzeQBz06KYOTySAG/dZ6sTpy363kVb9H1QdLAPV09J5OopiVTUNrAyw+rX/2LnYd7ZlIOXuxunDwlnbloUZ6VGER2s/fpKqSM00fcyAd4enDsqhnNHxdDQ2MT6fcUs2XaIxdsPcf976dz/XjozhlndP0MHBDo7XKWUC9BE34t5uLsxZXA4UwaH86v5qew6XMEn6Xm8uDKLc59ayQ+nD+b2M4fir906SvVrxzyaJyL/EJHDIpLewfRZIlIqIpvt4QGHafNEZKeI7BKRe7szcNWaiDAsKpDb5wxj6S9mcfHYOJ5bvpu5jy/nf9/mar18pfqxrpy28TIw7xjzrDTGjLWHhwBExB34K3AukAZcISJpJxOs6prwAG8eWzCGhTefToifF7e8vpHv/2MtewoqnR2aUkfRMsVHe/vttxERuuuklGP+pjfGrBCRpBNY9yRglzEmC0BE3gQuArqnwLI6polJYXxw2zT+9dU+Hv8sg3OeWMGNMwdz6+yh+Hpp6WTlGrRMcWvl5eU89dRTTJ48udvW2V0nYp8uIltE5H8iMsIeFwcccJgn2x7XLhG5UUTWi8j6/Pz8bgpLebi78YNpg/j8F2cwf3QMzyzdxdzHl/PZ1jztzlEuq7+WKQarrs8999yDj0/3nT3XHUfpNgKJxpgKETkPeA847gINxpgXgBfAOo++G+JSDgYE+vDEZWO5/LSB3P9+Ojf+awNnpgzgwQtGkBDu5+zwlAvJ+/3vqd3evWWKvVNTiP7lL49rmf5Ypnjjxo0cOHCA+fPn89hjjx3X+9WZk070xpgyh8cfi8izIhIB5AADHWaNt8cpJ5o8OJyP7pjBy1/u5cklGcx9Yjk/njWEm88Ygo+nduco19G2TPG1115LZmYmIkJ9fX27yzSXKfb29m4pUxwfH99qnuYyxUBLmeKAgICjyhS/8MIL7W6jbdfN+++/31KmGGgpU+yY6B3LFAPtliluamriZz/72Skp2nbSiV5EooFDxhgjIpOwuoMKgRJgmIgMwkrwlwNXnuz21MnzdHfjRzMHc8GYWB7+aBtPLsnknY05/PbCEcxOGeDs8JSTHW/L+1Tpb2WKy8vLSU9Pb3lteXl5XHjhhSxatKhLxyE605XTK98A1gDJIpItIj8UkZtF5GZ7lkuBdBHZAjwNXG4sDcBtwKfAduC/xpj27xagnCI62IdnrhzP6zdMxtNd+MHL67jx1fVkF1c5OzSlWukPZYqDg4MpKChg79697N27lylTpnRLkoeunXXTcWeVNf0Z4JkOpn0MfHxioameMm1oBP/7yUxeWrWHpz/PZO7jy7n9zGHcMGOQ3thcuYT+Uqb4VNGiZqqVgyXV/O7DbfwvPY/BEf789qIRzBgW6eyw1CmmRc36dplirXOrWokN8eVvV0/glesnYYBrXlrLra9vJLe02tmhKXVKvfjii4wdO5YRI0ZQWlqqZYpPNW3Ru4bahkZeWJ7FM0t34e4mnJ0WxfjEUMYNDCUlJhBPrYffZ2iLvnfRMsWq23h7uHP7nGFcPC6OJxZnsGpXAe9tPmhPc2N0fDDjEkIZnxDCuIRQooK0PLJSrkgTvTqmgWF+PH7ZWIwxHCytYdP+YjbtL2HT/mJe/nIvL6xoAiA22IdxCaGMSwhhXEIII2KD9dx8pVyAJnrVZSJCXIgvcSG+nD86FrC6d7bnlrNxXzGbDljJ/6NvcwHwdBfSYoJakv/4hFDiQ331vrdK9TBN9OqkeHu4M3ZgCGMHhrSMO1xew+b9JS2J/z/rDvDy6r0ARAR4MXbgkcQ/Oj5Y6+UrdYrpN0x1uwGBPpw9IpqzR0QD0NDYxM5D5XZ3TwmbDhSzZPshADzchAvHxnLTzCEkR+sdsfqjwsJC5syZA1hXg7q7u7eUE1i7di1eXl4dLrt+/XpeffXVVgXM2jN16tRuqWC5bNkyLrroopZSCRERESxZsqTD+ZOSkli/fj0RERGtxrdXpROsi8HuuuuulovDbrvtNm644YaTjlsTvTrlPNzdGBEbzIjYYK6ekghASVUdmw+UsGxnPv9Zd4B3NuZwZsoAbpo5mEmDwrR7px/RMsWtXXbZZTzzTLvXoJ4wPT9OOUWInxezkgfw4IUjWH3vmfz8rOFsOVDCZS98xXeeXc0n6bk0Nrneqb+qZ/TnMsWngrboldOF+ntx+5xh/GjmYN7akM2LK7K4+bWNDIrw50czBvPd8XF69k4PWvnfDAoOVHTrOiMGBjDje8OPa5n+WKYYrLtLrVixguHDh/PEE08wcODAduc7HtqiVy7Dx9Oda6YksvQXs/jrleMJ8Pbgl+9+y/Q/LuWvS3dRWtV+aVrVN7UtU7xgwQJGjhzJnXfeydat7ddHbC5THBER0VKmuK3mMsVubm4tZYp37NhxVJnijsyYMYPNmzezefNmfvWrX7Fu3bqWMsUeHh4tZYodOZYpDgoKardMMcAFF1zA3r17+eabbzjrrLO49tpru/ReHYu26JXLcXcT5o+O4bxR0azJKuT55Vk89ulOnl26iysmJXD99EHEhvg6O8w+63hb3qdKfytTDNbximY33HADd999d7esV1v0ymWJCFOHRPDK9ZP4+I4ZnD0imn+u3svMPy3lZ//dzM68cmeHqHpIfyhTDJCbm9vyeNGiRd1WlkJb9KpXSIsN4onLxvLzs4fz0qo9vLnWOlNndnIkN50xhMl6pk6f1l/KFD/99NMsWrQIDw8PwsLCum2npkXNVK9UXFnHa1/t4+XVeymsrGPswBBuPmMwZ6VF4+6mCf94aVEzLVOslMtpPlPny3vP5OGLR1JcVcfNr21k7uPL+ffX+6mpb3R2iKqX0TLFPUxb9Op4NTYZPknP47nlu/k2p5RgX09mDIvgjOGRnDE8kgFaWbNT2qLvXbRMseqXWp2ps7uQdzblsCIjnw+/sQ5upUQHckaylfQnJobh5aE/Ztsyxuhxjl7gRBrnmuhVnyIiTB0awdShERhj2JFXzvKMfJbvzOcfq/bw/PIs/L3cOX1IhJX4h0WSEO7n7LCdzsfHh8LCQsLDwzXZuzBjDIWFhfj4HN8v1GN23YjIP4DzgcPGmJHtTL8KuAcQoBy4xRizxZ621x7XCDR09LOiLe26UadCRW0Da3YXsjzjMMsz8jlQZN0ecVCEf0sXz5TB4fh69b+rcOvr68nOzqampsbZoahj8PHxIT4+/qgrfjvruulKop8JVACvdpDopwLbjTHFInIu8KAxZrI9bS8w0RhTcDwvRBO9OtWMMewtrGL5Tivpr8kqpKa+CS8PNyYPCmtJ/EMHBGgLV/UKJ5Xo7RUkAR+2l+jbzBcKpBtj4uzne9FEr3qBmvpG1u0tYvnOfJZn5JN52Kr1EhvswxnJkcwcFsnUoREE+3oeY01KOUdPJvpfACnGmBvs53uAYsAAzxtjXuhk2RuBGwESEhIm7Nu375hxKXWqHCypZkWGlfRXZRZQXtuAu5uQGhNIanQQqTFBpNiPQ/07rpeuVE/pkUQvIrOBZ4HpxphCe1ycMSZHRAYAi4HbjTErOlpHM23RK1dS39jE5gMlLN+Zz5bsErbnllFQUdcyPTrIh9SYQFJigkiJDiQtJohBEf54uOuZParnnPLTK0VkNPB34NzmJA9gjMmx/x4WkXeBScAxE71SrsTT3Y3TksI4LSmsZVx+eS3bc8vYkVfG9txytueWsWpXAfWNVsPJy8ON4VEBpNit/9ToQFJjtPWvnOOkE72IJADvANcYYzIcxvsDbsaYcvvx2cBDJ7s9pVxBZKA3kYGRzBwe2TKurqGJ3fkVrZL/sp35LNyQ3TJPVJD3keQfYyX/QRH+eGrrX51Cx0z0IvIGMAuIEJFs4DeAJ4Ax5jngASAceNY+O6H5NMoo4F17nAfwb2PMJ6fgNSjlErw83OwEHsR3xh0Zn19ey468MnbYyX97Xjmrd2e1av3/YGoSPz87WS/kUqeElkBQygnqG+3Wf245KzLyeWdTDqPignnq8rEMjgxwdniqF9KiZkq5GE93N1Kig7h4XByPXzaWF66ZwIHiKs7/yyr+u/7ACV3mrlRHNNEr5QLOHhHNJz+ZyZj4EO5e+A23v7GJ0mq9daLqHprolXIR0cE+vHbDZO46J5n/pedx3lMrWb+3yNlhqT5AE71SLsTdTbh19lAW3nw67m7C955fw1NLMmlobHJ2aKoX61vVK1c8Bp7+EBh9ZAiIBi+tTqh6l3EJoXx0x3QeeH8rTyzJYNWufJ68fBxxelN0dQL6zlk3xsDvY6G+6uhp3sEQGHUk8bfdETQ/9vI/elmlnOzdTdnc/95W3AQevWQ0542KcXZIygWddAmEnnbCp1caA1VFUJEH5blQfsj6W3EIyvOsocL+21h39PLeQRAQdfSOIDgehp8DntqaUs6xr7CSO97czJYDJVw2cSC/uTANP6++9YNcnZz+k+i7yhioLm6d+NvuCJqHxlprmYBomPkLGH8teOhl7Krn1Tc28eSSDJ5dtptB4f48fcU4RsYFOzss5SI00Z8oY6CmBA5uhuV/hP1rIDgBZt0Doy8Hd21RqZ63encBP/vPFgora7lnXgrXTxuEm5vWzO/vNNF3B2Ng9+fwxcNwcBOED4VZ98GI74KbnrykelZxZR33vP0Nn207xMzhkfx5wWgGBOoN0PszvTK2O4jA0Lnwo6Vw2evg7gVv/xCemw47PrJ2BEr1kFB/L56/ZgIPXzySr7MKOe+plSzdedjZYSkXpYn+eIlA6vlw8yq45CVoqIE3r4QXz4Rdn2vCVz1GRLh6SiIf3D6diABvfvDPdfz2g63UNjQ6OzTlYjTRnyg3dxh1Kdy6Fi58Birz4bXvwj/Pg32rnR2d6keGRwXy3q3TuG5qEv/8ci8X/3U1uw6XOzss5UK0j767NNTCxleti7YqDsGQOXDmryBugrMjU/3I59sPcdfCb6iqa+BX56VyzohoIgO99Qbn/YAejO1JdVWw7u+w6gmoLoLk+VbCjxrh7MhUP3G4rIaf/XcLq3YVABDo48GQyACGDgho+Tt0QAADQ331dod9iCZ6Z6gth6/+Bqv/Yj0e+V2Y9UuIGOrsyFQ/0NRk+HpPERmHytl1uILd+RXsOlzB4fLalnm83N1IivBrtQMYEmkNvl7uToxenQhN9M5UVWQl+6+fsw7cjrkSzrgbQhOdHZnqh0qr68myk/6u/Ap2H65kd34F+woraXJIBXEhvi0t/yM7AX/CA7ydF7zqlCZ6V1CRD6seh3UvgWmCCdfCjF9AkNYtUc5X29DIvsIqawfg8Atgd34FNfVHKmeG+nmSGhPE1CHhTB8Wyai4YNz1Yi2XoInelZTmWAdsN/3Lej7sHBhzGQyfBx7aWlKupanJcLC02k76lew6XMGWAyVsyy0DINjXk6lDwpk2NIIZwyJIDNfCgM5y0oleRP4BnA8cNsaMbGe6AE8B5wFVwHXGmI32tGuBX9uzPmyMeeVY2+vTib5Z0R7roO23b1ln6fgEw4jvWKUVEqZY5+sr5aIKK2r5cnchqzLzWZVZwMHSGgAGhvkyfWgk04dGMG1oOCF+Wheqp3RHop8JVACvdpDozwNux0r0k4GnjDGTRSQMWA9MBAywAZhgjCnubHv9ItE3a2yAPctgy39gx4dWmeXQJBh9mTWED3F2hEp1yhhDVkElX+4qYGVmAV/tLqS8tgERGBUXzPShEUwfGsGEpFC8PfQg76nSLV03IpIEfNhBon8eWGaMecN+vhOY1TwYY25qb76O9KtE76i2HLZ/CN+8CVnLAQPxp8GYy62aOn5hzo5QqWNqaGxiS3YJqzILWbUrn037S2hoMvh4ujFpUDjTh4YzfWgkKdGBWoytG/VEov8QeNQYs8p+/jlwD1ai9zHGPGyPvx+oNsb8uZ113AjcCJCQkDBh3759XYqrzyrNsbp1vvkPHN4Gbp5WTfzRl1l/tT9f9RIVtQ18nVXIyswCVu0qYNfhCgAiAryYNjSipX8/Jljv93AyOkv0LlNn1xjzAvACWC16J4fjfMFxMP2nMO0nkPctbHnTSvw7PgSfEOu8/NGXw8BJ2p+vXFqAtwdzUqOYkxoFQG5pNasyC/hyVwGrdhXy/uaDAEwdEs5DF41k6IAAZ4bbJ3VXos8BBjo8j7fH5WC16h3HL+umbfYPIhAz2hrOegiyllldO5vfgPX/gNBBVit/zGUQNtjZ0Sp1TDHBviyYOJAFEwdijGFHXjlf7DjM88t3c+5TK7j5jCHcOnsoPp7an99duqvrZj5wG0cOxj5tjJlkH4zdAIy3Z92IdTC2qLNt9ds++uNRWw7bFllJf89KwMDAyVbSH/Ed7c9XvU5+eS2//3g7727KISHMj99dPJIzhkc6O6xeozvOunkDq2UeARwCfgN4AhhjnrNPr3wGmId1euUPjDHr7WWvB35pr+oRY8w/j7U9TfTHqTTb6tbZ8ibk77D684fOgZGXQPJ54K0/hVXvsXpXAb9+L52sgkrmj47hgfPTiArSm6oci14w1V8YA7lbIH0hpL8DZTng4WsdvB15CQw7Gzz1C6NcX21DI88vz+KZpbvwdnfjF+ckc/WURL0KtxOa6PujpiY48DWkvw1b34WqAvAKtG6aMvJSGHwGuHs6O0qlOrW3oJL7309nZWYBo+KC+f13RjEqXm+I3h5N9P1dYwPsXQHfvg3bP4DaUvALh7SLrJZ+wlS9761yWcYYPvgml999uI3Cilq+f3oSPz97OIE+2lBxpIleHdFQa93yMH0h7PyfdSVuYIx1QdbISyBuvJ6uqVxSaXU9//fZTv711T4iA7z5zQUjOG9UtN5UxdZvEv3n+z4nJTyFuIC4UxBVH1RXCRmfWC39XYuhsc4qvzDyEmvQm6UoF7TlQAm/fPdbth4s44zhkfzuopEkhPs5Oyyn6xeJvrqhmulvTKeuqY7UsFTmJs5lbsJcBofoueVdUl1iXYyV/rZVfsE0QmSqnfS/qzV3lEtpaGzi1TX7+L/PdtLQZLhjzjB+NGMwXh79twuyXyR6gAPlB/hi/xcs2beEzfmbARgUPIi5CXOZmziX1LBU/ZnXFRX5sO0968yd/faNzmPHwZQfWwdytT9fuYi80hoe+nArH3+bx9ABATx88UimDA53dlhO0W8SvaPDVYetpL9/Cevz1tNoGon1j2VO4hzmJsxl7ICxuIkmrGMqzbbO2tn8BhzeCjFj4OyHYdBMZ0emVIulOw5z//vpZBdXc8n4eH55Xkq/uxtWv0z0jkpqSlh6YCmf7/+c1QdXU99UT4RvBGcOPJM5iXM4Lfo0PN30CH6nmpqsi7K++B2UHrBulDL3tzAgxdmRKQVAdV0jf/kikxdWZBHg48F956awYMLAflMhs98nekcVdRWsylnF4n2LWZmzkuqGaoK8gpg1cBZzE+Zyeuzp+HjoRUUdqq+27n+78nGoq4Dx37dueh4Y5ezIlAIg41A5v343nbV7i5iYGMqCifGMiA1mWFRAn66Hr4m+AzUNNaw5uIYl+5ew7MAyyurK8PXwZUbcDOYmzmVm/Ez8PfXWaO2qLIQVf7LukuXubVXZnHobeOn7pZzPGMPCDdn88ZMdFFTUAeDpLgwbEMiI2CBGxgUzIjaI1Jgg/L1dpojvSdFE3wX1TfWsy1vH5/s+5/P9n1NYU4inmydTY6cyN3Eu5w06Dy93vS3aUQp3w5IHYfsiCIiGM38FY68Ct77bclK9R1OTYX9RFekHS9l6sIz0nFK2HSyjsNJK/iIwKMKfEbFW4reGYML8e993XRP9cWpsauSbgm9YvG8xn+/7nIOVBxkUPIj7p9zPadGnOS0ul7b/a/js15C9FgakWSWVh87Vi6+UyzHGcKislvQcK/lvtXcCOSXVLfPEBvuQFhvMyLiglp1ATLCPS5+1p4n+JBhjWJmzkj98/QeyK7K5YPAF/Hzizwn37Z+ncHXKGNj2vtXCL94Dg2fBWb+zaukr5eKKK+vYlmsl/vQc629WQSXNKTLM34sRsUGkxQYxNj6EuWlReLq7zpl7mui7QU1DDS988wL/3PpP/Dz8+OmEn3LJsEv0FM32NNTB+pdg+R+tC7HGXAFn/tq6a5ZSvUhlbQM78spaun22Hiwj41A59Y2GpHA/7jxrOBeMjnWJM3s00XejrJIsHv76YdblrWNM5Bjun3I/yWHJzg7LNVWXwKrH4avnrC6cKT+G6XeCT5CzI1PqhNU1NLFs52EeX5zBjrxyUqIDueucZM5MGeDUrh1N9N3MGMOHWR/y5/V/prS2lKtTr+bHY3+Mn6fW22hXyX74/Hfw7X/BLwJm3QsTrtMyyapXa2oyfPDNQR5fnMG+wiomJIZy1znJTrsyVxP9KVJaW8oTG57g7cy3ifaP5r5J93FmwpnODst15WyExQ/A3pUQPtS64Cplvh6wVb1afWMT/11/gKc/z+RQWS0zhkVw9zkpPV43XxP9Kbb58GYe+uohMoszmRU/i/sm30dsQKyzw3JNxkDGp1bCL9hp1cKf93urlo5SvVhNfSOvrtnLs8t2U1JVz7kjo/n52cMZOiCwR7avib4H1DfV8/q213l2y7MA3DzmZq5Ju0ZLK3SksQE2vQpLfw+VBTDuapjzAAQMcHZkSp2U8pp6Xly5h5dWZlFd38h3x8fz07nDiA89tV27muh7UG5FLn9Y+weWHljK0JCh3D/lfsZHjXd2WK6rphRWPGYdsPXwgTPuhsk3g0fvu2BFKUeFFbX8bdluXv1qH8YYrpqcyK2zhxIZeGqKrZ10oheRecBTgDvwd2PMo22mPwHMtp/6AQOMMSH2tEbgW3vafmPMhcfaXm9O9M2+2P8Ff1j7B/Iq8/jusO9y5/g7CfEJcXZYrqtgF3z6S8j8FMKGwLw/WDc1V6qXO1hSzV++yOS/67Pxcnfj+ulJ3DhzCMG+3ftr/6QSvYi4AxnAWUA2sA64whizrYP5bwfGGWOut59XGGMCjifgvpDoAarqq3huy3O8uu1VgryC+NnEn3HRkItc+uo6p8tcDJ/cB4WZMPQsOOf3EDnc2VEpddKy8it4YkkmH2w5SJCPBzfPGsJ1U5Pw8+qeWjsnm+hPBx40xpxjP78PwBjzhw7mXw38xhiz2H7ebxN9s4ziDH635ndszt/MhKgJ3D/lfoaE6B2bOtRQB+tehGWPWve0nXwzzLwLfEOcHZlSJ23rwVL+77MMvthxmMhAb24/cyiXn5Zw0nfHOtlEfykwzxhzg/38GmCyMea2duZNBL4C4o0xjfa4BmAz0AA8aox5r4Pt3AjcCJCQkDBh3759XXpxvUWTaeLdzHd5fMPjVNVXcd3I67hx9I34evg6OzTXVZFv1b/f+Cr4hcOc+2HcNVowTfUJ6/cW8adPd7J2TxHxob7cOXc4F4+Lw/0Er7LtyUR/D1aSv91hXJwxJkdEBgNfAHOMMbs722Zfa9E7Kqop4v/W/x+Ldi8i0jeSuYlzmRU/y7r5iV5A1L6Dm+GTe2H/GogeDef+ERKnOjsqpU6aMYYVmQU89ukO0nPKSI4K5P3bpuHjefyNmR7ruhGRTcCtxpjVHazrZeBDY8zCzrbZlxN9s3V563h126t8dfArahpr8Pf0Z1rsNGYNnMXM+JkEe/fsxRYuzxjY+g589gCUZVs3LT/rIQiOd3ZkSp20pibDJ1vzSM8p5e55J3bXtpNN9B5YB2PnADlYB2OvNMZsbTNfCvAJMMjYKxWRUKDKGFMrIhHAGuCijg7kNusPib5ZTUMNX+d+zdIDS1mevZyC6gLcxZ1xA8Yxa+AsZg2cRWJQorPDdB11VfDlU/Dlk4BYtXOm3QGe2gWm+rfuOL3yPOBJrNMr/2GMeUREHgLWG2MW2fM8CPgYY+51WG4q8DzQBLgBTxpjXjrW9vpTonfUZJrYWrC1JelnFGcAMCh4ELMGzmL2wNmMjhiNu/ZRW/VzFj9g3bg8eCCc/TtIu1jLKah+Sy+Y6qVyKnJYdmAZyw4sY33eehpMA6HeocyIn8HsgbOZGjtVC6ntXQX/uxcOfQuJ0+HcRyF6lLOjUqrHaaLvA8rryvky50uWZS9jRfYKyuvK8XTzZHLMZGYPnM3M+JlE+0c7O0znaGqEja9YFTJrSmD8tVb9e/8IZ0emVI/RRN/H1DfVs/nwZpYeWMqyA8s4UH4AgNSwVGYPnM1ZiWcxNHSoc4N0hupiWP4nWPuC9TxqBMSOh7gJEDceIlP01EzVZ2mi78OMMWSVZrV08WzJ34LBMDZyLJcOv5Szk87uf+fq5++ELW/CwY2QswlqS63xnv4QM8ZK+nH2DiAkUfv1VZ+gib4fKagu4KOsj1iYsZC9ZXsJ9ArkgsEXcOnwSxkWOszZ4fW8piYoyrKT/gZryP0GGmut6X7hrVv9seMhINK5MSt1AjTR90PGGNYfWs/CjIUs3reY+qZ6xkSO4dLhl3JO0jn9r5XvqLEeDm11SP6bIH87mCZrenBC61Z/zFjwPq4qHkr1OE30/VxxTTGLdi860sr3DOT8Iedz6fBLGR6qBcMAqK2AvG+OtPpzNkJJcxkOsfr34ybAsLMg9QLt61cuRxO9AqxW/oZDG3gr462WVv7oyNFcOsxq5ff7UzXbqiyAg5uOJP6c9VBVCKGDYOrtMPZKvVBLuQxN9OooJTUlVis/cyF7SvcQ4BnA+YOtVn5yWLKzw3NNTY2w82NY9aSV9P0jYfJNcNoN4Bvq7OhUP6eJXnXIGMPGwxtZmLGQz/Z+Rl1THaMjRrf05Wsrvx3GwL4vrYS/azF4BcCE62DKLVp7RzmNJnrVJSU1JXyQ9QELMxaSVZpFgGcA8wfPZ8HwBdrK70heOqx+Gr5daJ2mOep7Vu2dAanOjkz1M5ro1XExxrDp8CbeynirpZU/KmIU0+OmkxKWQkpYCjH+MXqnLEcl+2HNX63a+fVVMHweTPspJJ7u7MhUP6GJXp2w0tpSPtj9Ae/teo+M4gwM1v9LkFcQKWEpJIclkxqWSnJYMoOCB+Hp1s9r6lcVwdoX4evnoLoIBk6GaT+B4eeC28ndQUipzmiiV92iqr6KzJJMdhbtZHvRdnYW7SSjOINa++IjLzcvhoYOtXYAocmkhqcyPHQ4/p7+To7cCeqqYNNrsOYvVms/Itnq0hn1PfDwcnZ0qg/SRK9OmYamBvaV7WNH0Y5WQ0ltScs8CYEJLV0+zUOEb0T/6PppbIBt71kHbg99C4ExMOXH1sFbnyAnB6f6Ek30qkcZYzhUdYidRTtbJf/siuyWecJ8wkgNSyU1PJVzB53b9y/cMgZ2f24l/L0rwTsYTrseJt8CgVHOjk71AZrolUsorytnZ9FOdhYf2QHsKt5Fg2lgdORoFgxf0D/KM+RssO6StW0RuHvBmMute+D6hYNfGPhFWI+9/LXgmuoyTfTKZTVfuPVWxlst5RnmD57PguQFfb+VX7gbVv8FNv/7SJE1R+7edvJv3gGEtxnCrJr7zc99w8DTp+dfh3IJmuiVy2suz7AwcyGL9y62LtyyyzPMGzSvb7fy6yqhPM8qr9DuUHTkcWWBdXOVjngFtN4pnPMHiOzjO0wFaKJXvUzb8gz9qpXfFY0N1k1WOt0pFFh/v/t3iOiHN6Hph7rj5uDzgKewbg7+d2PMo22mXwc8BuTYo54xxvzdnnYt8Gt7/MPGmFeOtT1N9Ar6eStfqeN0UoleRNyBDOAsIBtYB1xhjNnmMM91wERjzG1tlg0D1gMTAQNsACYYY4o726YmetWWtvKV6lxnib4rl+pNAnYZY7KMMXXAm8BFXdz2OcBiY0yRndwXA/O6uKxSLUJ8Qvj+iO/z/kXv8/K8l5k5cCbvZL7DJYsu4aqPr+LdzHepqq9ydphKuaSuJPo44IDD82x7XFuXiMg3IrJQRAYe57JKdYmIMCFqAo/OeJTPF3zOXRPvoryunAdWP8Cct+bwyFePsLNop7PDVMqleHTTej4A3jDG1IrITcArwJnHswIRuRG4ESAhIaGbwlJ9WXMr/5q0a1pKLb+T+Q5v7nyT1LBUTos+jfFR4xk/YDyhPlovXvVfXemjPx140Bhzjv38PgBjzB86mN8dKDLGBIvIFcAsY8xN9rTngWXGmDc626b20asT1dyX//n+z/m24Fvqm+oBGBw8uCXpT4iaQGxArJMjVap7nezBWA+sg7FzsM6qWQdcaYzZ6jBPjDEm1378HeAeY8wU+2DsBmC8PetGrIOxRZ1tUxO96g61jbWkF6Sz8dBGNhzewJbDW6iorwAg2j+6JemPHzCewSGDcROtLql6r84S/TG7bowxDSJyG/Ap1umV/zDGbBWRh4D1xphFwB0iciHQABQB19nLFonI77B2DgAPHSvJK9VdvN29mRA1gQlRE/gRP6KxqZGM4gw2Ht7IxkMbWZu3lo/3fAxAiHcIYweMZcKACYyPGk9qeKqWXFZ9Rp+6YKpu/3484+IQd/dTEJXqa4wxHCg/wIZDG1qS//7y/QD4evgyOmK01d0TNZ7REaP1torKpfWLK2NNQwMZU6ch7u74z5hOwMwzCJg+DfeQkFMTpOqT8qvyW5L+xsMb2Vm0E4PBQzxIDU9lTOQYRkaMZGTESBICE/pHqWXVK/SPRF9XR9lni6lYsZzKlatoLC4GNzd8x4wh4IyZBMyciXdqqn4x1XEprytn8+HNLcl/a+HWlhutBHoFkhaexshwK/GPCB9BtH+0/o8pp+gXid6RaWykJj2diuUrqFixgpr0dAA8IiPxt5O+/9SpuAcEdFfIqp9oaGpgd8lu0gvS2Vq4lfSCdDKLM2kwDYBVZ7856Tf/DfcNd3LUqj/oN4l+x5pcQqL8iEwMxN39yBkUDQUFVKxcZbX2V31JU3k5eHjgN2ECATNnEnDGTLyGDNGWmDohtY21ZBRlkF6Ybu0ACraSVZrVcn/dGP8YRoSPYESElfzTwtMI8tK7S6nu1S8SfUN9Iy/euYKmBoOntzsxQ0OITw4lLjmEiIGBuLlZSdzU11O9eTMVK1ZQsXwFtRkZAHjGxh5p7U+ZgpuvFsxSJ66qvopthdtaWv1bC7dyoPzIReKJQYmtWv0pYSl6sFedlH6R6AGqy+vIySghe2cxOTuLKTlk1T7x9vMgdlgIccmhxCeHEhbr39J6r8/NpWLFSipWrKByzRpMVRXi5YXf5MlHWvt6pa7qBqW1pWwt2NqS/NML0zlcdRgAQUgISmi5qXpyaHL/ureuOmn9JtG3VVlS25L0czKKKSuoAcA30JO44aEtiT94gC8iQlNdHdXr17f07dft2QOAV1IS/jNmEDBzBn6nnYabj97FR3WP/Kp8thZuZUfRjpZ77La9t25KWArJYcmkhFo3Vk8MSsTdTU8hVq3120TfVllBNTkZxXbyL6GyxDp7wj/Yi7gUK+nHDQ8lKMLqtqnbv99q7S9fTtXatZjaWsTbG7/TTiNgxnT8Z8zEa1CStrhUt2p7b92dRTvJLMmkock64Ovj7sOw0GEtyT85LJnhocO166ef00TfDmMMpYerW7X4q8utuihBET6tWvz+Id401dRQtW49latWUrFyFXVZWQB4xsVZ5+3PmIHf5Cm4B/if0rhV/1TfWE9WaVar5L+jaAdldWWA1fWTGJR4pPUfltLS9aP6B030XWCMoehgpdXi31HMwcwSaqusFlRIlB8R8QGExvgTFuNPWKw/fnXFVK/5koqVK6las4amqirw9MRv3DgCZs7Af8YMvIcP19a+OmWMMeRV5rGjaAc7io8k/5yKnJZ5In0jSQ1PJS08jdQw62+UX5T+X/ZBmuhPQFOToTC7guydVtIvOlhBWWEN9hlzuLkLIVF+hMX4EzrAB/+aw3jv3gRrv6B+h3XzLY/ISKtvf8Z067z94GAnviLVX5TVlbUk/e2F29letJ2s0iyaTBNg9funhqeSFpZGWrg1xPjHaPLv5TTRd5P6ukZK8qooyq2k6GCl9Te3krKC6lY7gOBwLwKlHN/CPXhlrMevIAvf2gL8R49q6ebxGTECcdNqiapnVNVXkVGcwbbCbWwv2s62wm3sLtlNo2kErKJuqWGpLa3/tLA04gPjNfn3IproT7FWOwCHnYDjDkAw+DcU41e0F7+qXIIoIyI5isiRSfikpOCTmoJHhPanqp5T01BDZnFmq+TveNA30CuQtLC0Vl0/CUEJWs7ZRWmid5KGukaKHXYAxbmVFGaXUVZYC1gtJc/6CoJLdxNSupswCohMDMYvdTjeyVby90pK0mqcqsfUNdaRWZLJ9kIr8W8v3E5GcQZ1TXUA+Hv6Mzx0OElBSSQGJbb8HRg0EG93bydH379poncxDXWNFB+qIn9/OQe35ZObWURZmfU5uJl6gkr3EFKyy9oB1ObiPyQBn5QUvFOS8UlNxXt4sp7do3pMfVM9WSVZbCvcxrbCbWQUZ7C/fD8F1QUt8whCbEAsiUGJJAQmkBRs7QASgxKJ9Y/V8/57gCb6XqCytJa83aUc3FVCbmYJBdkVWB+NIbipiOCCHQTlbye4dDfedWV4Jjgk/5RUq+snWisnqp5TUVfBvvJ97Cvdx76yfewt28u+Mutx8528ADzdPBkYOLDVL4DmQa/87T6a6HuhupoGDmWVcXB3Cbm7SjiUVUZDvXXWRIBXHaENeQQd2kpg1lp8qw8jgFtwsJX8hw3Da/AgvAcNwmvQIDyi9HQ61XOMMRTWFLK/bP9RO4D9ZftbuoEA/Dz8WnYA8YHxxATEEOMfQ6x/LNH+0XoR2HHQRN8HNDY2kb+/nNxdpeTuKiF3dyk1FdYFXj6+QqR/NSE12QTmfIN3xjqksqxlWTc/P7ySkvAaNKjVDsArKUmLt6ke1djUSF5VHvtKW+8A9pbtJa8yr+UsoGYh3iHE+NvJP8BK/rEBsS3jwnzCtBFj00TfBxljKDlUxcFMK+nn7ippqeUD4O4peHuCl9Th0VCNR3Up7uWFuJfl41FfiWd9FZ4NVXgH+eAfHYb/wCgCBsfhNyQR7yFD9FeA6nENTQ3kV+WTW5nLwcqD5FXmcbDiILmVueRWWOOqG6pbLePt7k2Mf0zLDiDaP5pYf3tHEBBDtF80nu79496/muj7iYriWnJ3l1BWUE1NZQO1lfXUVNZTW9VAjf24pqKepsaOP3Npqrd2Ao3VeHk04e3rjk+gN75h/gQMCCI4LpTgQZEERwXiE+CpOwPVY4wxlNWVtUr8zTuDvMo8DlYebHWAGKyDxPdMuoerUq9yUtQ9p7NE79HFFcwDngLcgb8bYx5tM/1nwA1AA5APXG+M2WdPawS+tWfdb4y58IRehTqmgFBvhk2M6nQeYwwN9U32TsDeGVRZO4CqwyVU5RZRXVhPTUkDNZUNVFZBcWUT9YWGpqxqoBo4CIB7Uz2+UoW/Vz3+/kJAiBdBA/wJjgslZNAAghKjcPP2OvUvXPULIkKwdzDB3sGkhKW0O09dYx15lXnWrwJ7BzAqYlQPR+p6jtmiFxF3IAM4C8gG1gFXGGO2OcwzG/jaGFMlIrcAs4wxl9nTKowxx3XPPm3Ru5ammhpq9+6jKjuP0v1FlB0qp7yohopyQ2WtO1VNPtR4BFHv2fpjlqYGfOpL8aMKP696AvyFwBBPAiMDCIoLITghEq+YKDwiwvVaAaVO0sm26CcBu4wxWfbK3gQuAloSvTFmqcP8XwFXn3i4ytW4+fjgm5KMb0oyHd391DQ2UpObT/GeQ5TuL6T8UIW9M2ikstaXw41hHKjyhyqsHwRbAHMI79oMghPCCU6MJDDch8AwhyHcB09v3QEodbK6kujjgAMOz7OByZ3M/0Pgfw7PfURkPVa3zqPGmPfaW0hEbgRuBEjQOzr1OuLujm98NL7x0cR2ME9jfRPlBZWU7D1M6f5CyvLKKS/yocbXl0N7Stm94TBNTa1/YXr7exyV/Jv/BoT64BuoxwmUOpYu9dF3lYhcDUwEznAYnWiMyRGRwcAXIvKtMWZ322WNMS8AL4DVddOdcSnX4O7pRkhMICExgXD6kKOmNzUZqkprKS+qpbyomvLCGsqLaqkoqqE0v5rsHcXU17Y+/c7D042A5h1AqHerHUFQhB/+wV6Im+4IVP/WlUSfAwx0eB5vj2tFROYCvwLOMMbUNo83xuTYf7NEZBkwDjgq0Svl5iYEhFot9ZghR5d0NsZQW9VAeVGNvROwhgr7ecGB8pabxzRz93QjKNyH4EhfgiJ8CYr0Jdj+GxThg4endg2pvq8riX4dMExEBmEl+MuBKx1nEJFxwPPAPGPMYYfxoUCVMaZWRCKAacCfuit41b+ICD7+nvj4exI5MLDdeRrqGqkorqWsoJqygmpKC2ooy6+2fhFklNDQ5heBf4i3vROwdwb2DiE40hcff+0WUn3DMRO9MaZBRG4DPsU6vfIfxpitIvIQsN4Yswh4DAgA3rK/GM2nUaYCz4tIE+CG1Ue/rd0NKdUNPLzcCYnyIyTq6EvnjTFUl9dbO4B8a0dQll9NaUE1B7YVsaO0rtX8Xj7uRxJ/868A+9hAQJg3Xj7d2vOp1CmjF0wpZauva6S8oIZShx1AWfMOoaCGxoamVvN7+3m0JP2AUB8C2/z1D/HG3UNrt6uecdIXTCnVH3h6uRMWa90TuC3TZKgoqbWOCRTXUGEfJC4vrqWiuIZDWWXUVLY+PoCAX5BXq+QfEOpNYNiRXwV+gXqwWJ16muiV6gJxk5ZTPDtSX9to7QSKm3cI1s6goriGooOV7EsvpKGu9a8CN3chINSb8eckMmJG3Kl+Gaqf0kSvVDfx9HYnNNqf0Oj2bwrjeNaQ406gvKgWvyAtFaFOHU30SvWQrpw1pNSpoEeKlFKqj9NEr5RSfZwmeqWU6uM00SulVB+niV4ppfo4TfRKKdXHaaJXSqk+ThO9Ukr1cS5Z1ExE8oF9J7h4BFBwzLlcQ2+KFXpXvL0pVuhd8famWKF3xXsysSYaYyLbm+CSif5kiMj6jiq4uZreFCv0rnh7U6zQu+LtTbFC74r3VMWqXTdKKdXHaaJXSqk+ri8m+hecHcBx6E2xQu+KtzfFCr0r3t4UK/SueE9JrH2uj14ppVRrfbFFr5RSyoEmeqWU6uP6TKIXkXkislNEdonIvc6OpzMiMlBElorINhHZKiI/cXZMxyIi7iKySUQ+dHYsxyIiISKyUER2iMh2ETnd2TF1RETutP8H0kXkDRHp+F6FTiAi/xCRwyKS7jAuTEQWi0im/TfUmTE26yDWx+z/g29E5F0RCXFiiK20F6/DtJ+LiBGRiO7YVp9I9CLiDvwVOBdIA64QkTTnRtWpBuDnxpg0YApwq4vHC/ATYLuzg+iip4BPjDEpwBhcNG4RiQPuACYaY0YC7sDlzo3qKC8D89qMuxf43BgzDPjcfu4KXuboWBcDI40xo4EM4L6eDqoTL3N0vIjIQOBsYH93bahPJHpgErDLGJNljKkD3gQucnJMHTLG5BpjNtqPy7ESkcveGVpE4oH5wN+dHcuxiEgwMBN4CcAYU2eMKXFqUJ3zAHxFxAPwAw46OZ5WjDErgKI2oy8CXrEfvwJc3JMxdaS9WI0xnxljGuynXwHxPR5YBzp4bwGeAO4Guu1Mmb6S6OOAAw7Ps3HhxOlIRJKAccDXTg6lM09i/eM1OTmOrhgE5AP/tLua/i4i7d+t28mMMTnAn7FabrlAqTHmM+dG1SVRxphc+3EeEOXMYI7D9cD/nB1EZ0TkIiDHGLOlO9fbVxJ9ryQiAcDbwE+NMWXOjqc9InI+cNgYs8HZsXSRBzAe+JsxZhxQiet0LbRi921fhLVzigX8ReRq50Z1fIx1frbLn6MtIr/C6jJ93dmxdERE/IBfAg9097r7SqLPAQY6PI+3x7ksEfHESvKvG2PecXY8nZgGXCgie7G6xM4UkdecG1KnsoFsY0zzL6SFWInfFc0F9hhj8o0x9cA7wFQnx9QVh0QkBsD+e9jJ8XRKRK4DzgeuMq594dAQrJ3+Fvv7Fg9sFJHok11xX0n064BhIjJIRLywDmgtcnJMHRIRwepD3m6MedzZ8XTGGHOfMSbeGJOE9b5+YYxx2VanMSYPOCAiyfaoOcA2J4bUmf3AFBHxs/8n5uCiB47bWARcaz++FnjfibF0SkTmYXU7XmiMqXJ2PJ0xxnxrjBlgjEmyv2/ZwHj7f/qk9IlEbx9suQ34FOuL8l9jzFbnRtWpacA1WK3jzfZwnrOD6kNuB14XkW+AscDvnRtO++xfHQuBjcC3WN9Hl7pcX0TeANYAySKSLSI/BB4FzhKRTKxfJY86M8ZmHcT6DBAILLa/Z885NUgHHcR7arbl2r9klFJKnaw+0aJXSinVMU30SinVx2miV0qpPk4TvVJK9XGa6JVSqo/TRK+UUn2cJnqllOrj/h+dNXFPeGegxwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Loss vs Epochs (LeNet+Adagrad)')\n",
    "plt.plot(LeNet_SGD_history[0].history['loss'], label='Training Fold 1')\n",
    "plt.plot(LeNet_SGD_history[1].history['loss'], label='Training Fold 2')\n",
    "plt.plot(LeNet_SGD_history[2].history['loss'], label='Training Fold 3')\n",
    "plt.plot(LeNet_SGD_history[3].history['loss'], label='Training Fold 4')\n",
    "plt.plot(LeNet_SGD_history[4].history['loss'], label='Training Fold 5')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-company",
   "metadata": {},
   "source": [
    "## Model Evaluation - confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "average-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "multiple-popularity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6719 - accuracy: 0.7692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6719048023223877, 0.7692307829856873]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score trained model.\n",
    "model_SGD.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "weird-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions.\n",
    "pred_SGD = model_SGD.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "automatic-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(data, row_labels, col_labels, ax=None, cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Create a heatmap from a numpy array and two lists of labels.\n",
    "    \"\"\"\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(top=True, bottom=False, labeltop=True, labelbottom=False)\n",
    "    # Show all ticks\n",
    "    ax.set_xticks(np.arange(data.shape[1]))\n",
    "    ax.set_yticks(np.arange(data.shape[0]))\n",
    "    # Label ticks with the respective list entries.\n",
    "    ax.set_xticklabels(col_labels)\n",
    "    ax.set_yticklabels(row_labels)\n",
    "    \n",
    "    ax.set_xlabel('Predicted Label') \n",
    "    ax.set_ylabel('True Label')\n",
    "    \n",
    "    return im, cbar\n",
    "\n",
    "def annotate_heatmap(im, data=None, fmt=\"d\", threshold=None):\n",
    "    \"\"\"\n",
    "    A function to annotate a heatmap.\n",
    "    \"\"\"\n",
    "    # Change the text's color depending on the data.\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            text = im.axes.text(j, i, format(data[i, j], fmt), horizontalalignment=\"center\",\n",
    "                                 color=\"white\" if data[i, j] > thresh else \"black\")\n",
    "            texts.append(text)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "hybrid-clinic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['Ennie','Jimmy','Biden','Elizabeth II','Teresa']\n",
    "\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(pred_SGD, axis=1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(Y_test, axis=1)\n",
    "# Errors are difference between predicted labels and true labels\n",
    "errors = (Y_pred_classes - Y_true != 0)\n",
    "\n",
    "Y_pred_classes_errors = Y_pred_classes[errors]\n",
    "Y_pred_errors = pred_SGD[errors]\n",
    "Y_true_errors = Y_true[errors]\n",
    "X_valid_errors = X_test[errors]\n",
    "\n",
    "cm = confusion_matrix(Y_true, Y_pred_classes) \n",
    "thresh = cm.max() / 2.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "im, cbar = heatmap(cm, labels, labels, ax=ax, cmap=plt.cm.Oranges, cbarlabel=\"count of predictions\")\n",
    "texts = annotate_heatmap(im, data=cm, threshold=thresh)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-kinase",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-fishing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-exchange",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
